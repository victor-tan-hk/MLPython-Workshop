{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed465863-3a35-4f65-a36e-76249e91a025",
   "metadata": {},
   "source": [
    "# Overfitting in linear / ridge / Lasso / Elasticnet regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31b70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import genfromtxt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4c97c",
   "metadata": {},
   "source": [
    "### Dataset with large number of feature variables - 104 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd67d5f5-25ff-47b3-afad-e4f1c4b99f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 104)\n",
      "(505,)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('boston_housing.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acff5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd20f4c5",
   "metadata": {},
   "source": [
    "## Checking overfitting on a Linear Regression model\n",
    "\n",
    "### First we fit the model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4081ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f649bc0",
   "metadata": {},
   "source": [
    "### Then we evaluate the fitted model using the training dataset and test dataset\n",
    "### Evaluation on test dataset is significantly worse than on training dataset\n",
    "### Classic indication of overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e929d999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.9353402315113886\n",
      "R^2 on test dataset :  0.84287087704203\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lr.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b016c",
   "metadata": {},
   "source": [
    "#### Standard linear regression performs badly because of overfitting. \n",
    "#### The model doesn't work well because the coefficient values for the feature variables don't have the best value possible due to the cost function optimization of linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d274a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.56000579e+02  1.82845512e+00 -5.92857666e+01  1.00201749e+01\n",
      " -2.53983517e+01  6.47104630e+01  4.73270639e+01 -3.88158553e+01\n",
      "  4.12557369e+01  2.50660785e+01 -6.62975377e+00  1.91927729e+01\n",
      "  2.33429828e+01  2.07014695e+01  2.41764970e+03  1.44806330e+03\n",
      "  9.70954290e+01 -6.06765721e+01  6.22991206e+01  6.00731344e+01\n",
      "  1.08168075e+02  9.44648254e+02 -1.97696260e+03  5.73260992e+02\n",
      "  9.17325284e-01  5.98900993e+01 -4.89503909e+00 -1.66244529e+01\n",
      "  2.45990765e+00 -5.56656273e+01  1.19101421e+01 -1.91814930e+00\n",
      " -2.12154187e+01 -2.53092085e+01  4.37918484e+01 -8.14296976e+00\n",
      "  1.23883990e+01 -2.32651036e+01  3.08203488e+01 -3.41834532e+00\n",
      " -8.19474516e+00  4.47099319e+01  7.06819308e+00  1.97265795e+00\n",
      "  1.73647824e+01  1.01707112e+00 -6.99336097e+00  1.61714772e+01\n",
      " -1.30004585e+01  1.00201749e+01 -2.43804133e+01 -3.34558107e+01\n",
      "  5.47222956e+00  1.96658675e+01 -1.52626564e+01  3.68338940e+01\n",
      " -1.49900353e+01  3.64322407e+00 -4.95778327e+00  3.81139426e+00\n",
      "  4.02029523e+01 -2.10483178e+01  8.51221542e+01 -2.74012944e+01\n",
      "  5.97475590e+01 -4.68434398e+01 -3.96027247e+00  4.94302318e+01\n",
      "  1.36448560e+01 -4.55531998e+01 -5.05116712e+00 -2.96095194e+00\n",
      " -7.86043693e+01 -6.93389434e+00 -8.32741338e+00 -3.69174549e+01\n",
      "  3.44660007e+00 -9.42565207e+00  3.11378922e+01 -2.27712603e+01\n",
      "  1.76882167e+00 -1.90616461e+01 -4.99929681e+01  6.00794679e+01\n",
      " -1.61335807e+01 -2.01318542e+01 -1.78642320e+01 -1.29216161e+01\n",
      "  4.07625869e+01 -8.44616327e+01  8.96165084e+01 -3.17300129e+01\n",
      " -5.54483101e-01 -2.46956019e+01 -1.48710146e+01  2.32168596e+01\n",
      " -7.50594568e+00 -1.67460976e+01  6.42513818e+00  1.38621765e+01\n",
      "  1.02588072e+01 -2.09428004e+00 -9.78176838e+00  1.88269054e+01]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2d906",
   "metadata": {},
   "source": [
    "## Checking overfitting on a Ridge Regression model\n",
    "\n",
    "### Again, we first fit the model on the training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff9198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.7).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4355b",
   "metadata": {},
   "source": [
    "### Then we evaluate the fitted model using the training dataset and test dataset\n",
    "### Evaluation on test dataset is nearly the same as that on training dataset\n",
    "### This could be an optimal model fit for the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175203e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.8711041719414669\n",
      "R^2 on test dataset :  0.8537431288976209\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = ridge.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = ridge.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064e384",
   "metadata": {},
   "source": [
    "#### Ridge regression performs better because regularization results in better values for the feature variables due to improved cost function optimization compared to linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7043c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.63163728e+00 -2.01357526e+00 -9.31241432e-01  4.70491189e-01\n",
      "  6.13803123e-01  9.24673064e+00  1.32661845e+00 -5.89940351e+00\n",
      "  6.12801980e+00 -5.18288062e-01 -1.93801736e+00  1.65574330e+00\n",
      " -4.18613434e+00  8.49937034e-01  7.77475363e-03 -1.01490325e+00\n",
      "  9.79343319e-01 -1.23998120e+00 -1.79557595e+00 -1.33340573e+00\n",
      " -1.88092745e-01 -2.16664461e+00 -1.80464253e+00 -1.56801113e+00\n",
      " -2.06058804e+00 -3.14974976e-01  2.71007136e+00 -2.05272772e+00\n",
      "  1.85022711e-01 -3.12763249e-01  4.25457983e+00 -1.22807420e+00\n",
      " -8.06748932e-02  2.84577736e-01  1.25283968e+00  1.14542188e+00\n",
      " -1.91867976e+00 -1.52941703e+00  3.95825389e+00  1.49120568e+00\n",
      "  2.10246654e+00 -3.76239367e+00  3.25157502e+00 -4.57288694e+00\n",
      "  1.32909263e+00  3.25873498e+00 -3.82935635e+00  5.10514782e-01\n",
      " -4.57592649e+00  4.70491189e-01 -5.82378759e+00 -3.58162522e+00\n",
      "  2.66297661e+00 -1.37757804e+00  1.87556317e+00  2.89532122e+00\n",
      "  2.61912179e-01  2.35327862e+00 -3.49188312e+00 -1.56462779e+00\n",
      " -3.61639326e+00 -2.73135077e+00 -2.14828619e+00 -2.31753455e+00\n",
      " -1.55017969e+00 -3.72755528e+00 -1.58647366e+00 -7.24970338e-01\n",
      "  1.87777548e+01 -1.51078109e+00  2.77106282e+00 -8.75590920e+00\n",
      " -1.02993766e+01 -8.08002314e+00  9.71251887e+00 -1.02623731e+01\n",
      "  1.56590147e+00 -3.50587671e+00  5.02598390e+00  6.39477789e-01\n",
      " -1.47118288e+00 -1.52441206e+00 -5.56036104e+00  2.82741815e+00\n",
      " -3.46119959e-01 -2.66714480e+00  1.02034435e+00 -6.02812620e+00\n",
      "  2.88999869e-01 -8.13391199e-01  4.72394091e-01  2.31450051e+00\n",
      "  3.73130083e+00 -8.34548240e+00 -2.88676005e-01  2.09317520e+00\n",
      " -4.96261225e-01 -8.01543155e+00  1.86182250e+00 -1.92461798e+00\n",
      "  1.28496490e+00  8.46586636e-01 -7.63838219e+00  1.25736964e+01]\n"
     ]
    }
   ],
   "source": [
    "print(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc81893a",
   "metadata": {},
   "source": [
    "## Checking overfitting on a Lasso Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ae83f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=1.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2eb112",
   "metadata": {},
   "source": [
    "### Evaluation on test dataset and training dataset is awful !\n",
    "### This is a classic indication of underfitting - model is not a good fit for the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "726c8175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.2399356285166997\n",
      "R^2 on test dataset :  0.22726292823054306\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lasso.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = lasso.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843685b",
   "metadata": {},
   "source": [
    "#### Lasso performs badly because of underfitting. \n",
    "#### The model doesn't work well because most of the coefficients have become exactly zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f4ba992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.          0.         -0.          0.         -0.          0.\n",
      " -0.          0.         -0.         -0.         -0.          0.\n",
      " -5.239652   -0.          0.         -0.          0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.          0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.          0.          0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.         -0.\n",
      " -0.         -0.         -2.94821365 -0.         -0.          0.\n",
      " -0.         -0.         -0.          0.         -0.         -0.34924127\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.          0.\n",
      " -0.         -0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859d4ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features actually used : 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features actually used : {sum(lasso.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6edf04a",
   "metadata": {},
   "source": [
    "## Manual tuning of hyperparameter alpha to reduce underfitting in Lasso\r\n",
    "#### Different hyperparameter values create different models which might be a better fit for the dataset\r\n",
    "\r\n",
    "[Sci-kit learn documentation for Lasso regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)lm)\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9649fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.01, tol=1e-2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb874dbc-9ca8-4c1a-8382-a8eba96a337e",
   "metadata": {},
   "source": [
    "#### Evaluation on test dataset is nearly the same as that on training dataset\n",
    "####  Hyperparameter tuning has resulted in a more optimal model fit for the Lasso regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768a6fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.873030657197334\n",
      "R^2 on test dataset :  0.8536025481616855\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lasso.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = lasso.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5498aa",
   "metadata": {},
   "source": [
    "#### This time the coefficient values for the more significant variable columns are included in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c0df2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.          -0.          -0.           0.          -0.\n",
      "   0.           0.          -7.15687746  12.22619531   0.\n",
      "  -0.           0.          -0.          -0.          -0.\n",
      "  -0.           0.          -0.          -0.          -0.\n",
      "  -0.          -9.1779753   -0.          -0.          -0.\n",
      "  -0.           1.98743341  -0.           0.          -0.\n",
      "   0.          -0.           0.          -0.           0.\n",
      "   0.          -0.          -0.           1.1019535    0.\n",
      "   0.          -0.           2.61245355  -4.89671657   0.\n",
      "   2.62370235  -0.16967295   0.          -3.18012303   0.\n",
      "  -2.51401802  -1.61594818   2.2930954   -0.           1.9735909\n",
      "   0.           0.           1.13318507  -0.          -2.79370496\n",
      "  -2.2969382   -0.          -0.          -0.          -0.\n",
      "  -6.76431995  -0.          -0.          31.90763633  -0.\n",
      "   0.         -14.7441085  -10.89514275  -8.84532558   7.76660855\n",
      " -14.7993476    0.          -2.83200332   7.33316484   0.\n",
      "  -0.          -0.         -11.4865197    0.          -0.\n",
      "  -0.           0.          -0.          -0.          -0.\n",
      "   0.           0.           1.9466493  -17.15579426   0.\n",
      "   0.           0.          -6.42321446   0.           0.\n",
      "   0.           0.          -7.90525747  19.92403954]\n"
     ]
    }
   ],
   "source": [
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d2f25f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features actually used : 32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features actually used : {sum(lasso.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228f5c9",
   "metadata": {},
   "source": [
    "### Checking overfitting on a ElasticNet Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07dc7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_net = ElasticNet(alpha=0.01, l1_ratio=0.01, tol=1e-2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1989dc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.8068701710913826\n",
      "R^2 on test dataset :  0.8048163676558451\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = elastic_net.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = elastic_net.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4fb6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
