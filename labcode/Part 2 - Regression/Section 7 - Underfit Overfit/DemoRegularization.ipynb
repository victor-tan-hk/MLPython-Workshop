{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b31b70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import genfromtxt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4c97c",
   "metadata": {},
   "source": [
    "### Dataset with large number of feature variables - 104 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9730dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 104)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "dataset = genfromtxt('https://raw.githubusercontent.com/m-mehdi/tutorials/main/boston_housing.csv', delimiter=',')\n",
    "X = dataset[:,:-1]\n",
    "y = dataset[:,-1]\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acff5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd20f4c5",
   "metadata": {},
   "source": [
    "### Checking overfitting on a Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4081ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f649bc0",
   "metadata": {},
   "source": [
    "### Evaluation on test dataset is significantly worse than on training dataset\n",
    "### Classic indication of overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e929d999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.9520519609032733\n",
      "R^2 on test dataset :  0.6074721959665701\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lr.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b016c",
   "metadata": {},
   "source": [
    "#### Standard linear regression performs badly because of overfitting. \n",
    "#### The model doesn't work well because the coefficient values for the feature variables don't have the best value possible due to the cost function optimization of linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8d274a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.12710947e+02 -5.22432068e+01 -1.31898815e+02 -1.20041365e+01\n",
      " -1.55107129e+01  2.87163342e+01  5.47040992e+01 -4.95346659e+01\n",
      "  2.65823927e+01  3.70620316e+01 -1.18281674e+01 -1.80581965e+01\n",
      " -1.95246830e+01  1.22025403e+01  2.98078144e+03  1.50084257e+03\n",
      "  1.14187325e+02 -1.69700520e+01  4.09613691e+01 -2.42636646e+01\n",
      "  5.76157466e+01  1.27812142e+03 -2.23986944e+03  2.22825472e+02\n",
      " -2.18201083e+00  4.29960320e+01 -1.33981515e+01 -1.93893485e+01\n",
      " -2.57541277e+00 -8.10130128e+01  9.66019367e+00  4.91423718e+00\n",
      " -8.12114800e-01 -7.64694179e+00  3.37837099e+01 -1.14464390e+01\n",
      "  6.85083979e+01 -1.73753604e+01  4.28128204e+01  1.13988209e+00\n",
      " -7.72696840e-01  5.68255921e+01  1.42875996e+01  5.39551110e+01\n",
      " -3.21709644e+01  1.92709675e+01 -1.38852338e+01  6.06343266e+01\n",
      " -1.23153942e+01 -1.20041365e+01 -1.77243899e+01 -3.39868183e+01\n",
      "  7.08999816e+00 -9.22538241e+00  1.71980268e+01 -1.27718431e+01\n",
      " -1.19727581e+01  5.73871915e+01 -1.75331865e+01  4.10103194e+00\n",
      "  2.93666477e+01 -1.76611772e+01  7.84049424e+01 -3.19098015e+01\n",
      "  4.81752461e+01 -3.95344813e+01  5.22959055e+00  2.19982410e+01\n",
      "  2.56483934e+01 -4.99982035e+01  2.91457545e+01  8.94267456e+00\n",
      " -7.16599297e+01 -2.28147862e+01  8.40660981e+00 -5.37905422e+00\n",
      "  1.20137322e+00 -5.20877186e+00  4.11452351e+01 -3.78250760e+01\n",
      " -2.67163851e+00 -2.55217108e+01 -3.33982030e+01  4.62272693e+01\n",
      " -2.41509169e+01 -1.77532970e+01 -1.39723701e+01 -2.35522208e+01\n",
      "  3.68353800e+01 -9.46890859e+01  1.44302810e+02 -1.51158659e+01\n",
      " -1.49513436e+01 -2.87729579e+01 -3.17673192e+01  2.49551594e+01\n",
      " -1.84384534e+01  3.65073948e+00  1.73101122e+00  3.53617137e+01\n",
      "  1.19553429e+01  6.77025947e-01  2.73452009e+00  3.03720012e+01]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2d906",
   "metadata": {},
   "source": [
    "### Checking overfitting on a Ridge Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fff9198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.7).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4355b",
   "metadata": {},
   "source": [
    "### Evaluation on test dataset is slightly worse than on training dataset\n",
    "### This could be an optimal model fit for the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "175203e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.8957405768115358\n",
      "R^2 on test dataset :  0.7614807948118889\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = ridge.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = ridge.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064e384",
   "metadata": {},
   "source": [
    "#### Ridge regression performs better because regularization results in better values for the feature variables due to improved cost function optimization compared to linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c7043c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.50621924e+00 -2.11678911e+00 -1.69158947e+00 -1.39618680e-01\n",
      "  1.60062726e-01  9.31427114e+00  4.76956483e-01 -5.56235430e+00\n",
      "  4.72632620e+00 -8.23255769e-01 -1.37993788e+00  1.18515649e+00\n",
      " -3.69120088e+00  9.14612863e-01  3.54636199e-03 -8.76814786e-01\n",
      "  9.85262089e-01 -1.58410643e+00 -1.52248147e+00 -1.54938713e+00\n",
      " -3.16457443e-02 -1.93071784e+00 -1.59122380e+00 -1.46511186e+00\n",
      " -1.61431014e+00 -6.30795079e-01  2.79754845e+00 -2.42159726e+00\n",
      "  4.65327122e-01 -4.96611258e-01  5.72262805e+00 -2.04878131e+00\n",
      "  3.58355553e-02  8.33936325e-01 -3.93835799e-01  3.77348305e-01\n",
      " -1.72478428e+00 -3.39883756e+00  3.86694415e+00  9.33171449e-01\n",
      "  2.11290564e+00 -4.14653457e+00  2.84785566e+00 -3.83353343e+00\n",
      "  2.13808310e+00  3.57326283e+00 -2.66422497e+00 -2.64111830e-01\n",
      " -3.92026709e+00 -1.39618680e-01 -6.31004004e+00 -3.85599897e+00\n",
      "  3.41709098e+00 -1.02194018e+00  3.29935139e+00  2.56981274e+00\n",
      "  1.33978535e+00  2.38957144e+00 -3.00921598e+00 -1.12884164e+00\n",
      " -3.22795350e+00 -2.51279133e+00 -1.17201248e+00 -3.19932234e+00\n",
      " -1.61811217e+00 -3.11291346e+00  9.27269824e-01 -1.38156424e+00\n",
      "  1.80783561e+01 -1.72322135e+00  2.41370288e+00 -9.28961303e+00\n",
      " -9.61047925e+00 -9.00186932e+00  1.09526572e+01 -8.50583937e+00\n",
      "  6.15169407e-01 -1.48014196e+00  3.27717446e+00 -3.07090611e-01\n",
      " -1.64414341e+00 -6.08874101e-01 -5.50197349e+00  1.69853815e+00\n",
      "  7.77039089e-01 -1.16604818e+00  1.53781346e-01 -5.83417924e+00\n",
      "  5.26385975e-02  1.25508777e+00  1.98355209e+00  2.37725404e+00\n",
      "  1.53999470e+00 -8.36610664e+00  9.58774608e-01  2.01077765e+00\n",
      " -1.48811614e+00 -8.11820825e+00  2.39213578e+00 -2.45959900e+00\n",
      "  7.07555615e-01  1.56163198e+00 -6.52313961e+00  1.27111208e+01]\n"
     ]
    }
   ],
   "source": [
    "print(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc81893a",
   "metadata": {},
   "source": [
    "### Checking overfitting on a Lasso Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ae83f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=1.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2eb112",
   "metadata": {},
   "source": [
    "### Evaluation on test dataset and training dataset is awful !\n",
    "#### This is a classic indication of underfitting - model is not a good fit for the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "726c8175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.29323768991114596\n",
      "R^2 on test dataset :  0.20937503255272272\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lasso.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = lasso.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843685b",
   "metadata": {},
   "source": [
    "#### Lasso performs badly because of underfitting. \n",
    "#### The model doesn't work well because most of the coefficients have become exactly zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f4ba992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.          0.         -0.          0.         -0.          0.\n",
      " -0.          0.         -0.         -0.         -0.          0.\n",
      " -5.3529079  -0.          0.         -0.          0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.          0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.          0.          0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.          0.\n",
      " -0.         -1.05063037 -3.3104274  -0.         -0.          0.\n",
      " -0.         -0.         -0.          0.         -0.         -0.41386744\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.          0.\n",
      " -0.         -0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "859d4ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features actually used : 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features actually used : {sum(lasso.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6edf04a",
   "metadata": {},
   "source": [
    "### Tuning of hyperparameter alpha to reduce underfitting in Lasso\n",
    "#### Different hyperparameter values create different models which might be a better fit for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9649fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.01, tol=1e-2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "768a6fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.8955681364442507\n",
      "R^2 on test dataset :  0.7660240830347568\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lasso.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = lasso.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5498aa",
   "metadata": {},
   "source": [
    "#### This time the coefficient values for the more significant variable columns are included in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c0df2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -8.80667134e+00\n",
      "  1.24181345e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -2.90779264e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -8.54659728e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  2.33256129e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -1.65371847e-02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  2.60668517e-02  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  4.47615503e-02 -1.80975950e+00\n",
      "  0.00000000e+00  3.25973213e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -4.46033185e+00 -2.00949936e+00\n",
      "  3.99444538e+00 -0.00000000e+00  4.31197312e+00  0.00000000e+00\n",
      "  0.00000000e+00  8.85575461e-02 -0.00000000e+00 -7.69700989e-01\n",
      " -4.28194566e+00 -0.00000000e+00 -0.00000000e+00 -2.82973132e+00\n",
      " -0.00000000e+00 -1.51228658e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  3.03508252e+01 -1.32458110e+00  0.00000000e+00 -1.26334531e+01\n",
      " -1.15624044e+01 -1.15545129e+01  1.16402596e+01 -8.89801331e+00\n",
      "  0.00000000e+00 -0.00000000e+00  3.05655240e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -9.43514614e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -9.33229283e+00  4.25437064e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.51737528e+01  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -7.46630263e+00  1.91856802e+01]\n"
     ]
    }
   ],
   "source": [
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d2f25f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features actually used : 33\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features actually used : {sum(lasso.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228f5c9",
   "metadata": {},
   "source": [
    "### Checking overfitting on a ElasticNet Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07dc7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_net = ElasticNet(alpha=0.01, l1_ratio=0.01, tol=1e-2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1989dc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 on training dataset :  0.8354121139215439\n",
      "R^2 on test dataset :  0.6975711194094201\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = elastic_net.predict(X_train)\n",
    "print('R^2 on training dataset : ', r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = elastic_net.predict(X_test)\n",
    "print('R^2 on test dataset : ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4fb6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
