{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CazISR8X_HUG"
   },
   "source": [
    "# Multiple Linear Regression for Startups with Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOyqYHTk_Q57"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_YHJjnD_Tja"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgC61-ah_WIz"
   },
   "source": [
    "## Importing the dataset\n",
    "\n",
    "To make things simple, we usually structure the dataset so that the target variable column is the last column in the table\n",
    "\n",
    "*  **X typically denotes the feature variables**, which are all the columns in the table except the last one\n",
    "* **y typically denotes the single target variable**, which is the last column in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrxyEKGn_ez7"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1586353652778,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "GOB3QhV9B5kD",
    "outputId": "4a05377a-2db2-43fc-b824-a0710448baee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables of the entire dataset\n",
      "[[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']\n",
      " [144372.41 118671.85 383199.62 'New York']\n",
      " [142107.34 91391.77 366168.42 'Florida']\n",
      " [131876.9 99814.71 362861.36 'New York']\n",
      " [134615.46 147198.87 127716.82 'California']\n",
      " [130298.13 145530.06 323876.68 'Florida']\n",
      " [120542.52 148718.95 311613.29 'New York']\n",
      " [123334.88 108679.17 304981.62 'California']\n",
      " [101913.08 110594.11 229160.95 'Florida']\n",
      " [100671.96 91790.61 249744.55 'California']\n",
      " [93863.75 127320.38 249839.44 'Florida']\n",
      " [91992.39 135495.07 252664.93 'California']\n",
      " [119943.24 156547.42 256512.92 'Florida']\n",
      " [114523.61 122616.84 261776.23 'New York']\n",
      " [78013.11 121597.55 264346.06 'California']\n",
      " [94657.16 145077.58 282574.31 'New York']\n",
      " [91749.16 114175.79 294919.57 'Florida']\n",
      " [86419.7 153514.11 0.0 'New York']\n",
      " [76253.86 113867.3 298664.47 'California']\n",
      " [78389.47 153773.43 299737.29 'New York']\n",
      " [73994.56 122782.75 303319.26 'Florida']\n",
      " [67532.53 105751.03 304768.73 'Florida']\n",
      " [77044.01 99281.34 140574.81 'New York']\n",
      " [64664.71 139553.16 137962.62 'California']\n",
      " [75328.87 144135.98 134050.07 'Florida']\n",
      " [72107.6 127864.55 353183.81 'New York']\n",
      " [66051.52 182645.56 118148.2 'Florida']\n",
      " [65605.48 153032.06 107138.38 'New York']\n",
      " [61994.48 115641.28 91131.24 'Florida']\n",
      " [61136.38 152701.92 88218.23 'New York']\n",
      " [63408.86 129219.61 46085.25 'California']\n",
      " [55493.95 103057.49 214634.81 'Florida']\n",
      " [46426.07 157693.92 210797.67 'California']\n",
      " [46014.02 85047.44 205517.64 'New York']\n",
      " [28663.76 127056.21 201126.82 'Florida']\n",
      " [44069.95 51283.14 197029.42 'California']\n",
      " [20229.59 65947.93 185265.1 'New York']\n",
      " [38558.51 82982.09 174999.3 'California']\n",
      " [28754.33 118546.05 172795.67 'California']\n",
      " [27892.92 84710.77 164470.71 'Florida']\n",
      " [23640.93 96189.63 148001.11 'California']\n",
      " [15505.73 127382.3 35534.17 'New York']\n",
      " [22177.74 154806.14 28334.72 'California']\n",
      " [1000.23 124153.04 1903.93 'New York']\n",
      " [1315.46 115816.21 297114.46 'Florida']\n",
      " [0.0 135426.92 0.0 'California']\n",
      " [542.05 51743.15 0.0 'New York']\n",
      " [0.0 116983.8 45173.06 'California']]\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables of the entire dataset\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VadrvE7s_lS9"
   },
   "source": [
    "## Encoding categorical data (state column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wV3fD1mbAvsh"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# This does one hot encoding\n",
    "# ct = ColumnTransformer(transformers=[('encoder', \n",
    "#  OneHotEncoder(), [3])], remainder='passthrough')\n",
    "\n",
    "# This does dummy encoding\n",
    "# which is the preferred encoding approach\n",
    "ct = ColumnTransformer(transformers=[('encoder', \n",
    "  OneHotEncoder(categories='auto',drop='first',sparse_output=False), [3])], remainder='passthrough')\n",
    "\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1586353657759,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "4ym3HdYeCGYG",
    "outputId": "ce09e670-cf06-4a1c-f5b0-89422aae0496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with the state categorical column dummy encoded into 2 columns\n",
      "[[0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [0.0 1.0 86419.7 153514.11 0.0]\n",
      " [0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [0.0 0.0 22177.74 154806.14 28334.72]\n",
      " [0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [0.0 0.0 0.0 135426.92 0.0]\n",
      " [0.0 1.0 542.05 51743.15 0.0]\n",
      " [0.0 0.0 0.0 116983.8 45173.06]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Dataset with the state categorical column dummy encoded into 2 columns\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kb_v_ae-A-20"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [0.0 1.0 542.05 51743.15 0.0]\n",
      " [0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [0.0 0.0 0.0 116983.8 45173.06]\n",
      " [0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [0.0 1.0 86419.7 153514.11 0.0]\n",
      " [0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [0.0 0.0 0.0 135426.92 0.0]\n",
      " [0.0 0.0 22177.74 154806.14 28334.72]]\n"
     ]
    }
   ],
   "source": [
    "print (X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling on the training and test data set and also target variable\n",
    "\n",
    "Remember that this must be done after the training and test split in order to avoid data leakage\n",
    "\n",
    "Typically, we don't scale the target variable except in certain special circumstances\n",
    "Here we demonstrate how this can be done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creating StandardScaler objects for feature scaling\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "# Scaling features (last 3 columns of X_train)\n",
    "X_train[:, -3:] = sc_X.fit_transform(X_train[:, -3:])\n",
    "X_test[:, -3:] = sc_X.transform(X_test[:, -3:])\n",
    "\n",
    "# Scaling the target variable y\n",
    "y_train_scaled = sc_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = sc_y.transform(y_test.reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 -0.3500645436227844 -0.7854710924793271 0.1011968019362538]\n",
      " [0.0 1.0 -0.555303187426314 -1.481174262628151 0.02734979174277092]\n",
      " [1.0 0.0 0.07935762307586282 0.8013338146656704 -0.551521323997471]\n",
      " [0.0 0.0 -0.5463823849331263 1.3250581707161837 0.07011683779235604]\n",
      " [1.0 0.0 0.4348537132854595 -0.3559866348200946 0.7514851578736048]\n",
      " [1.0 0.0 1.2694314288195354 0.855185185174973 0.986031184474382]\n",
      " [1.0 0.0 1.045250070905001 1.2807704710942711 0.44039999942558483]\n",
      " [0.0 1.0 -1.529843000700978 0.029420649133439825 -1.6218751012780783]\n",
      " [0.0 1.0 -1.5397625087372082 -2.767672641730695 -1.6372965026688253]\n",
      " [0.0 1.0 -0.13115188245559178 1.144977005989267 -0.7694999122824163]\n",
      " [0.0 1.0 0.927916133722245 -0.029920619212990152 0.4830316172654914]\n",
      " [1.0 0.0 -0.20932933131592557 -0.29937679537926 -0.8991541175619614]\n",
      " [0.0 0.0 -0.17870827894287686 0.2251351979981532 -1.2640164249123271]\n",
      " [0.0 0.0 0.13747089788308053 -0.06929437355020689 0.5038466577007928]\n",
      " [0.0 0.0 -1.0396762417942589 -1.0507669675123394 -0.43852106261266766]\n",
      " [0.0 0.0 0.09938347697265615 -0.3679031742499798 0.7818179989277446]\n",
      " [0.0 1.0 -1.2158017422009575 0.15416246935241742 -1.3494777810472085]\n",
      " [0.0 1.0 1.0582243665441649 0.9783675684696275 0.8867005055096748]\n",
      " [0.0 0.0 0.4401195955580429 0.4675474853678242 0.40923215274131525]\n",
      " [0.0 0.0 -0.15151937028841816 0.6243058551529852 -0.5198305559485576]\n",
      " [0.0 1.0 1.303611492773351 -0.9107351714849491 1.3017982548865463]\n",
      " [0.0 1.0 0.49781134864570625 0.837706512410103 0.6514913504683245]\n",
      " [0.0 0.0 -0.9289721246515195 -0.1871695723258425 -0.23769074738733695]\n",
      " [0.0 0.0 -1.5514977859885914 -0.24751711592316733 -1.2714049571244492]\n",
      " [0.0 0.0 1.968710847785411 1.0810671321179492 1.9581809612571657]\n",
      " [1.0 0.0 0.48063417620032334 0.1517705859153579 0.3863463242625676]\n",
      " [0.0 0.0 -0.5973919254506589 -2.7854421879174165 -0.04140286602981931]\n",
      " [0.0 1.0 0.11649007105102568 -0.9313385123897375 -0.49867240911600824]\n",
      " [0.0 0.0 1.3629007850333776 0.9196489932918887 -0.6028192132885423]\n",
      " [1.0 0.0 -0.08943162412651208 -0.6814233903950654 0.8312611211294444]\n",
      " [1.0 0.0 -0.9309329475657485 0.14156606641329023 -0.008214854885267122]\n",
      " [0.0 1.0 0.14561901880611441 1.173615097457821 0.790507597726031]\n",
      " [0.0 1.0 0.31947193909459937 1.1635979267068792 -1.6372965026688253]\n",
      " [0.0 0.0 1.1186784183579679 -0.5683134167614787 0.8329854818685873]\n",
      " [0.0 0.0 -0.7167135313068757 -1.5609558591515853 -0.21984184393674172]\n",
      " [1.0 0.0 -1.5230183324084707 -0.29261949289791545 0.7692632693055047]\n",
      " [0.0 1.0 1.5741368580485635 -0.1823100933791031 1.4665335503277532]\n",
      " [0.0 1.0 2.0282802885329074 0.5217329933404754 2.184047756769488]\n",
      " [0.0 0.0 -1.5514977859885914 0.46491494569993663 -1.6372965026688253]\n",
      " [0.0 0.0 -1.0713540211899808 1.2135072477208355 -1.4077916939760526]]\n"
     ]
    }
   ],
   "source": [
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31 -0.32 -0.09 -0.31  0.37  1.14  0.57 -1.1  -1.82 -0.21  0.51 -0.23\n",
      " -0.3   0.43 -0.94  0.22 -0.98  1.06  0.61 -0.05  1.17  0.39 -0.77 -2.34\n",
      "  2.03  0.79 -0.48 -0.02  1.15 -0.02 -0.46  0.05  0.33  1.   -0.7  -1.48\n",
      "  1.82  2.05 -1.65 -1.09]\n"
     ]
    }
   ],
   "source": [
    "print (y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15  0.86  0.91 -0.78  2.02 -0.11 -0.7  -0.3   0.02  1.4 ]\n"
     ]
    }
   ],
   "source": [
    "print (y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-McZVsQBINc"
   },
   "source": [
    "## Training the Multiple Linear Regression model \n",
    "\n",
    "Here, we use the both the scaled training dataset and scaled target variable to fit the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1586353664008,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ywPjx0L1BMiD",
    "outputId": "099836bc-4d85-4b4f-a488-093faf02e8cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNkXL1YQBiBT"
   },
   "source": [
    "## Generating predictions directly using the scaled test dataset\n",
    "\n",
    "For this case the predicted output is completely different from the results we got from the previous 2 models\n",
    "\n",
    "This is because the model is now trained using the scaled target variable\n",
    "\n",
    "Therefore the output is now in the scaled value range, which will not make sense to us\n",
    "\n",
    "To solve this, we need to do an inverse transform (reverse scaling) on the predicted output to get the actual output\n",
    "\n",
    "We will also need to do the same on the test target variable dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16 -0.15]\n",
      " [ 0.57  0.86]\n",
      " [ 0.57  0.91]\n",
      " [-0.93 -0.78]\n",
      " [ 1.71  2.02]\n",
      " [ 0.17 -0.11]\n",
      " [-1.03 -0.7 ]\n",
      " [-0.26 -0.3 ]\n",
      " [ 0.11  0.02]\n",
      " [ 1.45  1.4 ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_scaled = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred_scaled.reshape(len(y_pred_scaled),1), y_test_scaled.reshape(len(y_test_scaled),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inverse transform to obtain the original target variable values\n",
    "\n",
    "We now do an inverse transform on both the predicted target variable values and the actual target variable values\n",
    "\n",
    "The comparison output now should now be identical to what we have seen in the earlier models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1586353666678,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "TQKmwvtdBkyb",
    "outputId": "493436bf-a4ae-4374-ca16-0b0c25d19457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103015.2  103282.38]\n",
      " [132582.28 144259.4 ]\n",
      " [132447.74 146121.95]\n",
      " [ 71976.1   77798.83]\n",
      " [178537.48 191050.39]\n",
      " [116161.24 105008.31]\n",
      " [ 67851.69  81229.06]\n",
      " [ 98791.73  97483.56]\n",
      " [113969.44 110352.25]\n",
      " [167921.07 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_scaled = regressor.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predictions to get actual values\n",
    "y_pred_actual = sc_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_actual = sc_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Display predicted vs actual values\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred_actual .reshape(len(y_pred_actual ), 1), y_test_actual.reshape(len(y_test_actual), 1)), 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing evaluation metrics using scaled values\n",
    "* R Square \n",
    "* Mean Square Error(MSE) / Root Mean Square Error(RMSE)\n",
    "* Mean Absolute Error(MAE)\n",
    "\n",
    "If we now use the scaled values of target variable for the predicted and actual test output, the value of MSE / RMSE / MAE will now change drastically compared to earlier models. \n",
    "\n",
    "\n",
    "This is because as explained earlier, RMSE and MAE both are roughly in the same units or magnitude range as the target variable\n",
    "\n",
    "The scaled target variable is in the range of -2.0 to 2.0, so RMSE and MAE are in the same range as well \n",
    "\n",
    "\n",
    "On the other hand, the value of R2 stays the same. This is because R2 explains how much the variance between the target variable is caused by the feature variables.\n",
    "\n",
    "It is therefore not affected by the scaled target variable values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score :  0.9347068473282423\n",
      "MSE:  0.050995021405404364\n",
      "RMSE :  0.22582077274999385\n",
      "MAE :  0.1856954945799993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"R2 score : \", r2_score(y_test_scaled, y_pred_scaled))\n",
    "print(\"MSE: \", mean_squared_error(y_test_scaled, y_pred_scaled))\n",
    "print(\"RMSE : \" ,np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled)))\n",
    "print(\"MAE : \" , mean_absolute_error(y_test_scaled, y_pred_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing evaluation metrics using actual values\n",
    "\n",
    "* R Squared \n",
    "* Mean Square Error(MSE) / Root Mean Square Error(RMSE)\n",
    "* Mean Absolute Error(MAE)\n",
    "\n",
    "If we now use the actual values for the target variable for the predicted and actual test output from the inverse transform that we performed earlier,\n",
    "than the result will be identical to that of the previous 2 models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score :  0.9347068473282424\n",
      "MSE:  83502864.03257754\n",
      "RMSE :  9137.990152794953\n",
      "MAE :  7514.2936596406125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"R2 score : \", r2_score(y_test_actual,y_pred_actual))\n",
    "print(\"MSE: \", mean_squared_error(y_test_actual, y_pred_actual))\n",
    "print(\"RMSE : \" ,np.sqrt(mean_squared_error(y_test_actual, y_pred_actual)))\n",
    "print(\"MAE : \" , mean_absolute_error(y_test_actual,y_pred_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhYhte6t7H4wEK4xPpDWT7",
   "name": "Multiple Linear Regression",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
