{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CazISR8X_HUG"
   },
   "source": [
    "# Multiple Linear Regression for Startups: NumPy arrays version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOyqYHTk_Q57"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_YHJjnD_Tja"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgC61-ah_WIz"
   },
   "source": [
    "## Importing the dataset\n",
    "\n",
    "To make things simple, we usually structure the dataset so that the target variable column is the last column in the table\n",
    "\n",
    "*  **X typically denotes the feature variables**, which are all the columns in the table except the last one\n",
    "* **y typically denotes the single target variable**, which is the last column in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrxyEKGn_ez7"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1586353652778,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "GOB3QhV9B5kD",
    "outputId": "4a05377a-2db2-43fc-b824-a0710448baee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables of the entire dataset\n",
      "[[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']\n",
      " [144372.41 118671.85 383199.62 'New York']\n",
      " [142107.34 91391.77 366168.42 'Florida']\n",
      " [131876.9 99814.71 362861.36 'New York']\n",
      " [134615.46 147198.87 127716.82 'California']\n",
      " [130298.13 145530.06 323876.68 'Florida']\n",
      " [120542.52 148718.95 311613.29 'New York']\n",
      " [123334.88 108679.17 304981.62 'California']\n",
      " [101913.08 110594.11 229160.95 'Florida']\n",
      " [100671.96 91790.61 249744.55 'California']\n",
      " [93863.75 127320.38 249839.44 'Florida']\n",
      " [91992.39 135495.07 252664.93 'California']\n",
      " [119943.24 156547.42 256512.92 'Florida']\n",
      " [114523.61 122616.84 261776.23 'New York']\n",
      " [78013.11 121597.55 264346.06 'California']\n",
      " [94657.16 145077.58 282574.31 'New York']\n",
      " [91749.16 114175.79 294919.57 'Florida']\n",
      " [86419.7 153514.11 281574.31 'New York']\n",
      " [76253.86 113867.3 298664.47 'California']\n",
      " [78389.47 153773.43 299737.29 'New York']\n",
      " [73994.56 122782.75 303319.26 'Florida']\n",
      " [67532.53 105751.03 304768.73 'Florida']\n",
      " [77044.01 99281.34 140574.81 'New York']\n",
      " [64664.71 139553.16 137962.62 'California']\n",
      " [75328.87 144135.98 134050.07 'Florida']\n",
      " [72107.6 127864.55 353183.81 'New York']\n",
      " [66051.52 182645.56 118148.2 'Florida']\n",
      " [65605.48 153032.06 107138.38 'New York']\n",
      " [61994.48 115641.28 91131.24 'Florida']\n",
      " [61136.38 152701.92 88218.23 'New York']\n",
      " [63408.86 129219.61 46085.25 'California']\n",
      " [55493.95 103057.49 214634.81 'Florida']\n",
      " [46426.07 157693.92 210797.67 'California']\n",
      " [46014.02 85047.44 205517.64 'New York']\n",
      " [28663.76 127056.21 201126.82 'Florida']\n",
      " [44069.95 51283.14 197029.42 'California']\n",
      " [20229.59 65947.93 185265.1 'New York']\n",
      " [38558.51 82982.09 174999.3 'California']\n",
      " [28754.33 118546.05 172795.67 'California']\n",
      " [27892.92 84710.77 164470.71 'Florida']\n",
      " [23640.93 96189.63 148001.11 'California']\n",
      " [15505.73 127382.3 35534.17 'New York']\n",
      " [22177.74 154806.14 28334.72 'California']\n",
      " [1000.23 124153.04 1903.93 'New York']\n",
      " [1315.46 115816.21 297114.46 'Florida']\n",
      " [14505.73 135426.92 35634.17 'California']\n",
      " [542.05 51743.15 165265.1 'New York']\n",
      " [59808.86 116983.8 45173.06 'California']]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables of the entire dataset\")\n",
    "print(X)\n",
    "print (type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable of the entire dataset\n",
      "[192261.83 191792.06 191050.39 182901.99 166187.94 156991.12 156122.51\n",
      " 155752.6  152211.77 149759.96 146121.95 144259.4  141585.52 134307.35\n",
      " 132602.65 129917.04 126992.93 125370.37 124266.9  122776.86 118474.03\n",
      " 111313.02 110352.25 108733.99 108552.04 107404.34 105733.54 105008.31\n",
      " 103282.38 101004.64  99937.59  97483.56  97427.84  96778.92  96712.8\n",
      "  96479.51  90708.19  89949.14  81229.06  81005.76  78239.91  77798.83\n",
      "  71498.49  69758.98  65200.33  64926.08  49490.75  42559.73  35673.41\n",
      "  14681.4 ]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print (\"Target variable of the entire dataset\")\n",
    "print (y)\n",
    "print (type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VadrvE7s_lS9"
   },
   "source": [
    "## Perform dummy encoding on categorical variables in dataset\n",
    "\n",
    "Here, there is only one categorical variable column, State."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wV3fD1mbAvsh"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# This performs dummy encoding\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', \n",
    "  OneHotEncoder(categories='auto',drop='first',sparse_output=False), [3])], remainder='passthrough')\n",
    "\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1586353657759,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "4ym3HdYeCGYG",
    "outputId": "ce09e670-cf06-4a1c-f5b0-89422aae0496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables after dummy encoding on the State column\n",
      "[[0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [0.0 1.0 86419.7 153514.11 281574.31]\n",
      " [0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [0.0 0.0 22177.74 154806.14 28334.72]\n",
      " [0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [0.0 0.0 14505.73 135426.92 35634.17]\n",
      " [0.0 1.0 542.05 51743.15 165265.1]\n",
      " [0.0 0.0 59808.86 116983.8 45173.06]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables after dummy encoding on the State column\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "## Splitting original dataset into the Training set and Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kb_v_ae-A-20"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 rows in the training dataset\n",
      "\n",
      "The feature variable values are\n",
      "[[1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [0.0 1.0 542.05 51743.15 165265.1]\n",
      " [0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [0.0 0.0 59808.86 116983.8 45173.06]\n",
      " [0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [0.0 1.0 86419.7 153514.11 281574.31]\n",
      " [0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [0.0 0.0 14505.73 135426.92 35634.17]\n",
      " [0.0 0.0 22177.74 154806.14 28334.72]]\n",
      "\n",
      "The target variable values are\n",
      "[ 96778.92  96479.51 105733.54  96712.8  124266.9  155752.6  132602.65\n",
      "  64926.08  35673.41 101004.64 129917.04  99937.59  97427.84 126992.93\n",
      "  71498.49 118474.03  69758.98 152211.77 134307.35 107404.34 156991.12\n",
      " 125370.37  78239.91  14681.4  191792.06 141585.52  89949.14 108552.04\n",
      " 156122.51 108733.99  90708.19 111313.02 122776.86 149759.96  81005.76\n",
      "  49490.75 182901.99 192261.83  42559.73  65200.33]\n"
     ]
    }
   ],
   "source": [
    "print (f\"There are {len(X_train)} rows in the training dataset\\n\")\n",
    "print (\"The feature variable values are\")\n",
    "print (X_train)\n",
    "print (\"\\nThe target variable values are\")\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 rows in the test dataset\n",
      "\n",
      "The feature variable values are\n",
      "[[1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [1.0 0.0 142107.34 91391.77 366168.42]]\n",
      "\n",
      "The target variable values are\n",
      "[103282.38 144259.4  146121.95  77798.83 191050.39 105008.31  81229.06\n",
      "  97483.56 110352.25 166187.94]\n"
     ]
    }
   ],
   "source": [
    "print (f\"There are {len(X_test)} rows in the test dataset\\n\")\n",
    "print (\"The feature variable values are\")\n",
    "print (X_test)\n",
    "\n",
    "print (\"\\nThe target variable values are\")\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-McZVsQBINc"
   },
   "source": [
    "## Training the Multiple Linear Regression model using the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1586353664008,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ywPjx0L1BMiD",
    "outputId": "099836bc-4d85-4b4f-a488-093faf02e8cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNkXL1YQBiBT"
   },
   "source": [
    "## Generating predictions using the test dataset\n",
    "\n",
    "We generate predictions and then compare these visually with the actual values from the test dataset by printing them out\n",
    "\n",
    "For a real life ML project, this step is not necessary. We would only need to check the regression metrics (next cell) to \n",
    "determine evaluate how good or accurate this model is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1586353666678,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "TQKmwvtdBkyb",
    "outputId": "493436bf-a4ae-4374-ca16-0b0c25d19457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101624.21 103282.38]\n",
      " [126931.06 144259.4 ]\n",
      " [128394.7  146121.95]\n",
      " [ 70903.06  77798.83]\n",
      " [176773.07 191050.39]\n",
      " [121351.27 105008.31]\n",
      " [ 67273.41  81229.06]\n",
      " [ 94761.86  97483.56]\n",
      " [116616.43 110352.25]\n",
      " [164883.45 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common metrics for model evaluation in regression\n",
    "* R Squared \n",
    "* Mean Square Error(MSE) / Root Mean Square Error(RMSE)\n",
    "* Mean Absolute Error(MAE)\n",
    "\n",
    "When we evaluate metrics, we use the target variable (Profit Column) in test dataset as the ground truth\n",
    "and compare that with the predictions generated by the model for the feature variables in the test dataset\n",
    "\n",
    "R Squared is always between 0 (totally useless) and 1 (perfect accuracy)\n",
    "\n",
    "RMSE and MAE both are roughly in the same units or magnitude range as the target variable (Profit column)\n",
    "RMSE / MAE are in thousands (1000s) while Profit is in (100,000s)\n",
    "\n",
    "Therefore, RMSE / MAE will have different range of values, depending on the magnitude of the target variable column\n",
    "In other words, they are dataset specific\n",
    "\n",
    "They are good for **comparing between different models trained on the same dataset**\n",
    "\n",
    "Typically used in  data science competitions such as Kaggle !\n",
    "\n",
    "\n",
    "\n",
    "R Squared, on the other hand, is always between 0 and 1, regardless of the magnitude of the target variable column\n",
    "\n",
    "It is good for **assessing the accuracy of the model as a whole, and is therefore a more popular metric**\n",
    "\n",
    "It is also easier to explain and justify to non data-scientists ! \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score :  0.8921823057957278\n",
      "MSE:  137887142.69482076\n",
      "RMSE :  11742.535616076315\n",
      "MAE :  9847.582188257618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"R2 score : \", r2_score(y_test,y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE : \" ,np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"MAE : \" , mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model to generate predictions\n",
    "\n",
    "Assuming we are happy with the metrics for the model, we are now ready to use the model by providing it some values for the feature variables and generating a prediction for the target variable\n",
    "\n",
    "For e.g. assume we want to predict profit for a company in New York with the following situation\n",
    "\n",
    "\n",
    "RnD: 165000\n",
    "\n",
    "\n",
    "Admin: 135000\n",
    "\n",
    "\n",
    "Marketing: 475000\n",
    "\n",
    "\n",
    "To encode New York, we use State_Florida = 0 and State_New York = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted target variable value (profit) for that sample data point is  [194529.35]\n"
     ]
    }
   ],
   "source": [
    "# The format for the input that we want to generate predictions on must be the same format as the \n",
    "# training dataset that was used to train the model\n",
    "# This will be a 2D Numpy array\n",
    "\n",
    "sample_to_predict = [[0, 1, 165000, 135000, 475000]]\n",
    "profit_pred = regressor.predict(sample_to_predict)\n",
    "print (\"The predicted target variable value (profit) for that sample data point is \", profit_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhYhte6t7H4wEK4xPpDWT7",
   "name": "Multiple Linear Regression",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
