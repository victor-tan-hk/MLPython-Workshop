{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37puETfgRzzg"
   },
   "source": [
    "# Demonstrate some common data preprocessing steps : Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "## Importing the dataset (typically CSV format)\n",
    "\n",
    "To make things simple, we usually structure the dataset so that the **target variable (dependent variable)** column is the last column in the table, and all the preceding columns are **feature variable (independent variable)** columns\n",
    "\n",
    "*  **X typically denotes the feature variables**, which in this case will be all the columns in the table except the last one\n",
    "* **y typically denotes the single target variable**, which in this case is the last column in the table\n",
    "\n",
    "Note here that X is a Dataframe and y is a Series, so we can use all the standard methods for these two core Pandas objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwEPNDWySTKm"
   },
   "outputs": [],
   "source": [
    "df  = pd.read_csv('sample-data-proprocessing-v1.csv')\n",
    "df.index = df.index + 1 # Start index from 1 instead of 0, just to make it easier to interpret data\n",
    "X = df.iloc[  :  , :-1] # Accesses all columns except the last\n",
    "y = df.iloc[  :  , -1]  # Accesses the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "hCsz2yCebe1R",
    "outputId": "1e4cc568-4e51-4b38-9d46-4aa3f15204be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature variable columns in X are\n",
      "    Country   Age   Salary    Cost  Days\n",
      "1     Spain  21.0  11000.0     120     3\n",
      "2    France  45.0  32000.0     330     7\n",
      "3     Spain  43.0  60000.0     510    15\n",
      "4    France  40.0  80000.0     910     8\n",
      "5   Germany  74.0  59000.0     520     5\n",
      "6   Germany   NaN  92000.0     800   500\n",
      "7    France  51.0  43000.0     420     6\n",
      "8    France  74.0      NaN     720     8\n",
      "9    France  73.0  25000.0     930    15\n",
      "10    Spain  65.0  85000.0     410    13\n",
      "11    Spain  44.0  94000.0     620    12\n",
      "12  Germany  25.0  22000.0    -200     9\n",
      "13  Germany  75.0  52000.0     740     4\n",
      "14    Spain  34.0  15000.0     870    19\n",
      "15  Germany   NaN  54000.0     370     6\n",
      "16   France  48.0  31000.0     610     7\n",
      "17   France  58.0  80000.0     280    11\n",
      "18  Germany  32.0  56000.0  200000     8\n",
      "19    Spain  34.0  51000.0     330   900\n",
      "20   France  55.0  59000.0     630     5\n",
      "21    Spain  50.0  54000.0     340    10\n",
      "22  Germany  62.0      NaN     680     7\n",
      "23   France  44.0  45000.0     900     5\n",
      "24   France  39.0  18000.0     480    14\n",
      "25    Spain  38.0  33000.0     600    20\n",
      "26   France  51.0  95000.0     250    14\n",
      "27    Spain  46.0  80000.0     250    13\n",
      "28   France  74.0  82000.0     320    14\n",
      "29  Germany  72.0  37000.0     450    11\n",
      "30    Spain  80.0  98000.0    1000     6\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"The feature variable columns in X are\")\n",
    "print (X)\n",
    "print (type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eYrOQ43XcJR3",
    "outputId": "e0873b2a-3b08-4bab-ef0d-15b88858ca44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target variable column values are : \n",
      "1     Yes\n",
      "2      No\n",
      "3     Yes\n",
      "4      No\n",
      "5     Yes\n",
      "6     Yes\n",
      "7      No\n",
      "8      No\n",
      "9     Yes\n",
      "10     No\n",
      "11    Yes\n",
      "12     No\n",
      "13     No\n",
      "14    Yes\n",
      "15     No\n",
      "16     No\n",
      "17    Yes\n",
      "18    Yes\n",
      "19     No\n",
      "20     No\n",
      "21     No\n",
      "22    Yes\n",
      "23    Yes\n",
      "24     No\n",
      "25    Yes\n",
      "26     No\n",
      "27     No\n",
      "28    Yes\n",
      "29    Yes\n",
      "30     No\n",
      "Name: Purchased, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print (\"The target variable column values are : \")\n",
    "print(y)\n",
    "print (type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhfKXNxlSabC"
   },
   "source": [
    "## Checking for missing data and perform imputation if necessary\n",
    "\n",
    "Handling missing values is one of the most important aspects of data cleansing in the ML life cycle\n",
    "\n",
    "We first check for missing data in the numeric columns of X (Age, Salary, Cost and Days)\n",
    "\n",
    "If there are any, we can use any one of the many methods available to handle the missing values\n",
    "\n",
    "A simple approach is to simply impute the missing cells with either the **mean, median or mode of all the other values in that column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the numeric columns : \n",
      "Age       2\n",
      "Salary    2\n",
      "Cost      0\n",
      "Days      0\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data in 'Age' and 'Salary' columns\n",
    "missing_data_check = X[['Age', 'Salary', 'Cost', 'Days']].isnull().sum()\n",
    "print(\"Number of missing values in the numeric columns : \")\n",
    "print (missing_data_check)\n",
    "print (type(missing_data_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables X after imputation:\n",
      "     Country   Age   Salary    Cost  Days\n",
      "1     Spain  21.0  11000.0     120     3\n",
      "2    France  45.0  32000.0     330     7\n",
      "3     Spain  43.0  60000.0     510    15\n",
      "4    France  40.0  80000.0     910     8\n",
      "5   Germany  74.0  59000.0     520     5\n",
      "6   Germany  52.0  92000.0     800   500\n",
      "7    France  51.0  43000.0     420     6\n",
      "8    France  74.0  55107.0     720     8\n",
      "9    France  73.0  25000.0     930    15\n",
      "10    Spain  65.0  85000.0     410    13\n",
      "11    Spain  44.0  94000.0     620    12\n",
      "12  Germany  25.0  22000.0    -200     9\n",
      "13  Germany  75.0  52000.0     740     4\n",
      "14    Spain  34.0  15000.0     870    19\n",
      "15  Germany  52.0  54000.0     370     6\n",
      "16   France  48.0  31000.0     610     7\n",
      "17   France  58.0  80000.0     280    11\n",
      "18  Germany  32.0  56000.0  200000     8\n",
      "19    Spain  34.0  51000.0     330   900\n",
      "20   France  55.0  59000.0     630     5\n",
      "21    Spain  50.0  54000.0     340    10\n",
      "22  Germany  62.0  55107.0     680     7\n",
      "23   France  44.0  45000.0     900     5\n",
      "24   France  39.0  18000.0     480    14\n",
      "25    Spain  38.0  33000.0     600    20\n",
      "26   France  51.0  95000.0     250    14\n",
      "27    Spain  46.0  80000.0     250    13\n",
      "28   France  74.0  82000.0     320    14\n",
      "29  Germany  72.0  37000.0     450    11\n",
      "30    Spain  80.0  98000.0    1000     6\n"
     ]
    }
   ],
   "source": [
    "# If there are missing values present in any of the numeric columns\n",
    "if missing_data_check.any():\n",
    "\n",
    "    for column in ['Age', 'Salary', 'Cost', 'Days']:\n",
    "       if missing_data_check[column] > 0:\n",
    "\n",
    "           #Impute missing data with the mean of the existing values in the respective column\n",
    "           \n",
    "           X[column].fillna(X[column].mean(), inplace=True)\n",
    "\n",
    "           # You can also impute with the median of the existing values in the respective column\n",
    "           # \n",
    "           #X[column].fillna(X[column].median(), inplace=True)\n",
    "\n",
    "           # You can also impute with the mode of the existing values in the respective column\n",
    "\n",
    "           #mode_value = X[column].mode()[0]\n",
    "           #X[column].fillna(mode_value, inplace=True)\n",
    "\n",
    "\n",
    "           \n",
    "           # Round the imputed values to the nearest integer\n",
    "           # Not necessary, but helps in displaying the column values neatly\n",
    "           X[column] = X[column].round()\n",
    "\n",
    "# Display modified X dataframe after imputation\n",
    "print(\"Feature variables X after imputation:\\n\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to detect outliers and impute them with mean of non-outliers\n",
    "\n",
    "There are many **custom algorithms** available for detecting outliers based on statistical techniques, each of them has their specific weakness and advantages\n",
    "\n",
    "The range of values that are considered normal so that anything outside this range is **highly subjective**\n",
    "\n",
    "Some algorithms will miss picking up extremely low value or high value outliers, while others may mistake slightly high or low values within normal rage as outliers\n",
    "\n",
    "This particular algorithm will pick up extremely high value outliers but may miss extremely low value outliers \n",
    "\n",
    "Replacing the outlier values with the mean of the non-outlier values however is pretty straightforward\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_outliers(df, column):\n",
    "    # Calculate the first and third quartile\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Check if there are any outliers\n",
    "    outliers = ((df[column] < lower_bound) | (df[column] > upper_bound))\n",
    "    outlier_count = outliers.sum()\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "\n",
    "        print (f\"Number of outliers detecting for column '{column}' is {outlier_count}\")\n",
    "        \n",
    "        # Calculate mean of non-outlier values\n",
    "        non_outlier_mean = int(df[~outliers][column].mean())\n",
    "        \n",
    "        # Replace outliers with the mean of non-outlier values\n",
    "        df.loc[outliers, column] = non_outlier_mean\n",
    "        print(f\"Outliers detected and imputed in column '{column}' with mean value {non_outlier_mean}\")\n",
    "    else:\n",
    "        print(f\"No outliers detected in column '{column}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers detecting for column 'Cost' is 1\n",
      "Outliers detected and imputed in column 'Cost' with mean value 523\n",
      "Number of outliers detecting for column 'Days' is 2\n",
      "Outliers detected and imputed in column 'Days' with mean value 9\n"
     ]
    }
   ],
   "source": [
    "# Check and impute outliers for columns 'Cost' and 'Days'\n",
    "impute_outliers(X, 'Cost')\n",
    "impute_outliers(X, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables after detection and imputation of outliers\n",
      "    Country   Age   Salary  Cost  Days\n",
      "1     Spain  21.0  11000.0   120     3\n",
      "2    France  45.0  32000.0   330     7\n",
      "3     Spain  43.0  60000.0   510    15\n",
      "4    France  40.0  80000.0   910     8\n",
      "5   Germany  74.0  59000.0   520     5\n",
      "6   Germany  52.0  92000.0   800     9\n",
      "7    France  51.0  43000.0   420     6\n",
      "8    France  74.0  55107.0   720     8\n",
      "9    France  73.0  25000.0   930    15\n",
      "10    Spain  65.0  85000.0   410    13\n",
      "11    Spain  44.0  94000.0   620    12\n",
      "12  Germany  25.0  22000.0  -200     9\n",
      "13  Germany  75.0  52000.0   740     4\n",
      "14    Spain  34.0  15000.0   870    19\n",
      "15  Germany  52.0  54000.0   370     6\n",
      "16   France  48.0  31000.0   610     7\n",
      "17   France  58.0  80000.0   280    11\n",
      "18  Germany  32.0  56000.0   523     8\n",
      "19    Spain  34.0  51000.0   330     9\n",
      "20   France  55.0  59000.0   630     5\n",
      "21    Spain  50.0  54000.0   340    10\n",
      "22  Germany  62.0  55107.0   680     7\n",
      "23   France  44.0  45000.0   900     5\n",
      "24   France  39.0  18000.0   480    14\n",
      "25    Spain  38.0  33000.0   600    20\n",
      "26   France  51.0  95000.0   250    14\n",
      "27    Spain  46.0  80000.0   250    13\n",
      "28   France  74.0  82000.0   320    14\n",
      "29  Germany  72.0  37000.0   450    11\n",
      "30    Spain  80.0  98000.0  1000     6\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables after detection and imputation of outliers\")\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform one hot encoding on categorical variables in dataset\n",
    "\n",
    "This converts categorical variables into numeric format, since certain ML algorithms such as linear regression require all values in the dataset used to train the ML model to be numeirc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables after one hot encoding on the Country column\n",
      "    Age  Salary  Cost  Days  Country_France  Country_Germany  Country_Spain\n",
      "1    21   11000   120     3               0                0              1\n",
      "2    45   32000   330     7               1                0              0\n",
      "3    43   60000   510    15               0                0              1\n",
      "4    40   80000   910     8               1                0              0\n",
      "5    74   59000   520     5               0                1              0\n",
      "6    52   92000   800     9               0                1              0\n",
      "7    51   43000   420     6               1                0              0\n",
      "8    74   55107   720     8               1                0              0\n",
      "9    73   25000   930    15               1                0              0\n",
      "10   65   85000   410    13               0                0              1\n",
      "11   44   94000   620    12               0                0              1\n",
      "12   25   22000  -200     9               0                1              0\n",
      "13   75   52000   740     4               0                1              0\n",
      "14   34   15000   870    19               0                0              1\n",
      "15   52   54000   370     6               0                1              0\n",
      "16   48   31000   610     7               1                0              0\n",
      "17   58   80000   280    11               1                0              0\n",
      "18   32   56000   523     8               0                1              0\n",
      "19   34   51000   330     9               0                0              1\n",
      "20   55   59000   630     5               1                0              0\n",
      "21   50   54000   340    10               0                0              1\n",
      "22   62   55107   680     7               0                1              0\n",
      "23   44   45000   900     5               1                0              0\n",
      "24   39   18000   480    14               1                0              0\n",
      "25   38   33000   600    20               0                0              1\n",
      "26   51   95000   250    14               1                0              0\n",
      "27   46   80000   250    13               0                0              1\n",
      "28   74   82000   320    14               1                0              0\n",
      "29   72   37000   450    11               0                1              0\n",
      "30   80   98000  1000     6               0                0              1\n"
     ]
    }
   ],
   "source": [
    "# Perform one hot encoding on the 'Country' column in X\n",
    "X = pd.get_dummies(X, columns=['Country']).astype(int)\n",
    "\n",
    "print (\"Feature variables after one hot encoding on the Country column\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform label encoding on the target variable\n",
    "\n",
    "The target variable must also be encoded in numeric format for many ML models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable column original values\n",
      "1     Yes\n",
      "2      No\n",
      "3     Yes\n",
      "4      No\n",
      "5     Yes\n",
      "6     Yes\n",
      "7      No\n",
      "8      No\n",
      "9     Yes\n",
      "10     No\n",
      "11    Yes\n",
      "12     No\n",
      "13     No\n",
      "14    Yes\n",
      "15     No\n",
      "16     No\n",
      "17    Yes\n",
      "18    Yes\n",
      "19     No\n",
      "20     No\n",
      "21     No\n",
      "22    Yes\n",
      "23    Yes\n",
      "24     No\n",
      "25    Yes\n",
      "26     No\n",
      "27     No\n",
      "28    Yes\n",
      "29    Yes\n",
      "30     No\n",
      "Name: Purchased, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (\"Target variable column original values\")\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding the Yes and No as 1 and 0\n",
      "[1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "print (\"After encoding the Yes and No as 1 and 0\")\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting original dataset into the Training set and Test set\n",
    "\n",
    "This is a fundamental practice in ML and is important for:\n",
    "* Evaluating model performance correctly\n",
    "* Avoiding overfitting\n",
    "* Preventing data leakage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3333, random_state = 1)\n",
    "\n",
    "# We use a fixed value for the random state parameter so that the split will always use the same rows for the training and test data set \n",
    "# This is ensure reproducibility of this ML project, which is important to verify performance evaluations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 rows in the training dataset\n",
      "\n",
      "The feature variable values are\n",
      "    Age  Salary  Cost  Days  Country_France  Country_Germany  Country_Spain\n",
      "24   39   18000   480    14               1                0              0\n",
      "5    74   59000   520     5               0                1              0\n",
      "3    43   60000   510    15               0                0              1\n",
      "26   51   95000   250    14               1                0              0\n",
      "7    51   43000   420     6               1                0              0\n",
      "19   34   51000   330     9               0                0              1\n",
      "14   34   15000   870    19               0                0              1\n",
      "8    74   55107   720     8               1                0              0\n",
      "28   74   82000   320    14               1                0              0\n",
      "2    45   32000   330     7               1                0              0\n",
      "17   58   80000   280    11               1                0              0\n",
      "1    21   11000   120     3               0                0              1\n",
      "16   48   31000   610     7               1                0              0\n",
      "30   80   98000  1000     6               0                0              1\n",
      "29   72   37000   450    11               0                1              0\n",
      "10   65   85000   410    13               0                0              1\n",
      "9    73   25000   930    15               1                0              0\n",
      "13   75   52000   740     4               0                1              0\n",
      "12   25   22000  -200     9               0                1              0\n",
      "6    52   92000   800     9               0                1              0\n",
      "\n",
      "The target variable values are\n",
      "[0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print (f\"There are {len(X_train)} rows in the training dataset\\n\")\n",
    "print (\"The feature variable values are\")\n",
    "print (X_train)\n",
    "\n",
    "print (\"\\nThe target variable values are\")\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 rows in the test dataset\n",
      "\n",
      "The feature variable values are\n",
      "    Age  Salary  Cost  Days  Country_France  Country_Germany  Country_Spain\n",
      "18   32   56000   523     8               0                1              0\n",
      "22   62   55107   680     7               0                1              0\n",
      "11   44   94000   620    12               0                0              1\n",
      "20   55   59000   630     5               1                0              0\n",
      "15   52   54000   370     6               0                1              0\n",
      "21   50   54000   340    10               0                0              1\n",
      "27   46   80000   250    13               0                0              1\n",
      "4    40   80000   910     8               1                0              0\n",
      "25   38   33000   600    20               0                0              1\n",
      "23   44   45000   900     5               1                0              0\n",
      "\n",
      "The target variable values are\n",
      "[1 1 1 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print (f\"There are {len(X_test)} rows in the test dataset\\n\")\n",
    "print (\"The feature variable values are\")\n",
    "print (X_test)\n",
    "\n",
    "print (\"\\nThe target variable values are\")\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "This should be done (rather than before) after train test split to avoid data leakage that may contribute to poor model \n",
    "performance in production\n",
    "\n",
    "There are two commonly used types of feature scaling: **standardization** and **normalization**\n",
    "\n",
    "Here we are using **standardization**, which scales the data such that the distribution of values in the feature column has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "After standardization, most values will lie within the **range of approximately -3 and 3** (since ±3 standard deviations cover about 99.7% of data in a normal distribution).\n",
    "\n",
    "**fit_transform()** first performs a **fit()**, which computes the mean and standard deviation of the training data set, which is subsequently stored in **sc**\n",
    "Subsequently, it performs a **transform()**, which uses the mean and standard deviation in **sc** to scale the training data set\n",
    "\n",
    "Finally we use the same **sc** object (rather than creating a new one) to also feature scale the test dataset. This ensures that the same scaling parameters (mean and standard deviation) applied to the test data are identical to those used for the training data. This is important to prevent data leakage.\n",
    "\n",
    "Also note that we perform feature scaling only on the columns that were originally numeric, and do not include columns with numbers that result from categorical encoding such as one hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train.iloc[:, 0:4] = sc.fit_transform(X_train.iloc[:, 0:4])\n",
    "\n",
    "# Transform the test data\n",
    "X_test.iloc[:, 0:4] = sc.transform(X_test.iloc[:, 0:4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables in training dataset after standardization\n",
      "         Age    Salary      Cost      Days  Country_France  Country_Germany  \\\n",
      "24 -0.864214 -1.229152 -0.050749  0.958664               1                0   \n",
      "5   1.099909  0.246319  0.089249 -1.171700               0                1   \n",
      "3  -0.639743  0.282306  0.054249  1.195371               0                0   \n",
      "26 -0.190801  1.541854 -0.855739  0.958664               1                0   \n",
      "7  -0.190801 -0.329474 -0.260747 -0.934993               1                0   \n",
      "19 -1.144803 -0.041578 -0.575743 -0.224872               0                0   \n",
      "14 -1.144803 -1.337113  1.314233  2.142199               0                0   \n",
      "8   1.099909  0.106221  0.789240 -0.461579               1                0   \n",
      "28  1.099909  1.074022 -0.610742  0.958664               1                0   \n",
      "2  -0.527507 -0.725332 -0.575743 -0.698286               1                0   \n",
      "17  0.202024  1.002048 -0.750740  0.248542               1                0   \n",
      "1  -1.874335 -1.481061 -1.310733 -1.645114               0                0   \n",
      "16 -0.359154 -0.761320  0.404245 -0.698286               1                0   \n",
      "30  1.436616  1.649816  1.769227 -0.934993               0                0   \n",
      "29  0.987674 -0.545397 -0.155748  0.248542               0                1   \n",
      "10  0.594849  1.181983 -0.295746  0.721957               0                0   \n",
      "9   1.043791 -0.977242  1.524230  1.195371               1                0   \n",
      "13  1.156027 -0.005591  0.859239 -1.408407               0                1   \n",
      "12 -1.649864 -1.085203 -2.430719 -0.224872               0                1   \n",
      "6  -0.134683  1.433893  1.069236 -0.224872               0                1   \n",
      "\n",
      "    Country_Spain  \n",
      "24              0  \n",
      "5               0  \n",
      "3               1  \n",
      "26              0  \n",
      "7               0  \n",
      "19              1  \n",
      "14              1  \n",
      "8               0  \n",
      "28              0  \n",
      "2               0  \n",
      "17              0  \n",
      "1               1  \n",
      "16              0  \n",
      "30              1  \n",
      "29              0  \n",
      "10              1  \n",
      "9               0  \n",
      "13              0  \n",
      "12              0  \n",
      "6               0  \n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables in training dataset after standardization\")\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables in test dataset after standardization\n",
      "         Age    Salary      Cost      Days  Country_France  Country_Germany  \\\n",
      "18 -1.257039  0.138358  0.099749 -0.461579               0                1   \n",
      "22  0.426495  0.106221  0.649242 -0.698286               0                1   \n",
      "11 -0.583625  1.505867  0.439244  0.485250               0                0   \n",
      "20  0.033671  0.246319  0.474244 -1.171700               1                0   \n",
      "15 -0.134683  0.066384 -0.435744 -0.934993               0                1   \n",
      "21 -0.246918  0.066384 -0.540743  0.011835               0                0   \n",
      "27 -0.471390  1.002048 -0.855739  0.721957               0                0   \n",
      "4  -0.808097  1.002048  1.454231 -0.461579               1                0   \n",
      "25 -0.920332 -0.689345  0.369245  2.378906               0                0   \n",
      "23 -0.583625 -0.257500  1.419232 -1.171700               1                0   \n",
      "\n",
      "    Country_Spain  \n",
      "18              0  \n",
      "22              0  \n",
      "11              1  \n",
      "20              0  \n",
      "15              0  \n",
      "21              1  \n",
      "27              1  \n",
      "4               0  \n",
      "25              1  \n",
      "23              0  \n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables in test dataset after standardization\")\n",
    "print (X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing_tools.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
