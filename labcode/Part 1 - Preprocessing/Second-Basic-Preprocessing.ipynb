{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37puETfgRzzg"
   },
   "source": [
    "# Demonstrate some common data preprocessing steps: Version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "## Importing the dataset (typically CSV format)\n",
    "\n",
    "To make things simple, we usually structure the dataset so that the **target variable (dependent variable)** column is the last column in the table, and all the preceding columns are **feature variable (independent variable)** columns\n",
    "\n",
    "*  **X typically denotes the feature variables**, which in this case will be all the columns in the table except the last one\n",
    "* **y typically denotes the single target variable**, which in this case is the last column in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwEPNDWySTKm"
   },
   "outputs": [],
   "source": [
    "df  = pd.read_csv('sample-data-proprocessing-v2.csv')\n",
    "df.index = df.index + 1 # Start index from 1 instead of 0, just to make it easier to interpret data\n",
    "X = df.iloc[  :  , :-1] # Accesses all columns except the last\n",
    "y = df.iloc[  :  , -1]  # Accesses the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "hCsz2yCebe1R",
    "outputId": "1e4cc568-4e51-4b38-9d46-4aa3f15204be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature variable columns in X are\n",
      "    Country   Age   Salary  Staff      Cost   Days\n",
      "1     Spain  21.0  11000.0    NaN     120.0    3.0\n",
      "2       NaN   NaN      NaN    NaN       NaN    NaN\n",
      "3     Spain  43.0  60000.0    NaN     510.0   15.0\n",
      "4    France  40.0  80000.0    3.0     910.0    8.0\n",
      "5   Germany  74.0  59000.0    NaN     520.0    5.0\n",
      "6   Germany   NaN  92000.0    NaN     800.0  500.0\n",
      "7    France  51.0  43000.0    NaN     420.0    6.0\n",
      "8    France  74.0      NaN    6.0     720.0    8.0\n",
      "9    France  73.0  25000.0    NaN     930.0   15.0\n",
      "10      NaN   NaN  85000.0    NaN       NaN    NaN\n",
      "11    Spain  44.0  94000.0    NaN     620.0   12.0\n",
      "12  Germany  25.0  22000.0    NaN    -200.0    9.0\n",
      "13  Germany  75.0  52000.0    NaN     740.0    4.0\n",
      "14      NaN  34.0  15000.0    NaN     870.0   19.0\n",
      "15  Germany   NaN  54000.0    NaN     370.0    6.0\n",
      "16   France  48.0  31000.0   10.0     610.0    7.0\n",
      "17   France  58.0  80000.0    NaN     280.0   11.0\n",
      "18  Germany  32.0  56000.0    NaN  200000.0    8.0\n",
      "19    Spain  34.0  51000.0    NaN     330.0  900.0\n",
      "20   France  55.0  59000.0    NaN     630.0    5.0\n",
      "21    Spain  50.0  54000.0    NaN     340.0   10.0\n",
      "22  Germany  62.0      NaN   15.0     680.0    7.0\n",
      "23   France  44.0  45000.0    NaN     900.0    5.0\n",
      "24      NaN  39.0  18000.0    NaN     480.0   14.0\n",
      "25    Spain  38.0  33000.0    NaN     600.0   20.0\n",
      "26   France  51.0  95000.0    NaN     250.0   14.0\n",
      "27    Spain  46.0  80000.0    NaN     250.0   13.0\n",
      "28   France  74.0  82000.0   20.0     320.0   14.0\n",
      "29  Germany  72.0  37000.0    NaN     450.0   11.0\n",
      "30    Spain  80.0  98000.0    NaN    1000.0    6.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"The feature variable columns in X are\")\n",
    "print (X)\n",
    "print (type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eYrOQ43XcJR3",
    "outputId": "e0873b2a-3b08-4bab-ef0d-15b88858ca44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target variable column values are : \n",
      "1     Yes\n",
      "2      No\n",
      "3     Yes\n",
      "4      No\n",
      "5     Yes\n",
      "6     Yes\n",
      "7      No\n",
      "8      No\n",
      "9     Yes\n",
      "10    NaN\n",
      "11    Yes\n",
      "12     No\n",
      "13     No\n",
      "14    Yes\n",
      "15     No\n",
      "16     No\n",
      "17    Yes\n",
      "18    Yes\n",
      "19     No\n",
      "20     No\n",
      "21     No\n",
      "22    Yes\n",
      "23    Yes\n",
      "24     No\n",
      "25    Yes\n",
      "26     No\n",
      "27     No\n",
      "28    Yes\n",
      "29    Yes\n",
      "30     No\n",
      "Name: Purchased, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print (\"The target variable column values are : \")\n",
    "print(y)\n",
    "print (type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing data\n",
    "\n",
    "Another common issue are rows or columns in the dataset which have significantly more missing values than existing values\n",
    "\n",
    "In this case, it does not make sense to impute the mean, mode or median, because there is not adequate info to calculate them meaningfully\n",
    "\n",
    "So it would be better to just **completely remove those rows or columns** from the dataset\n",
    "\n",
    "If we are removing complete rows, we must also remember to remove the target variable values for those rows from the y series\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rows we are dropping are  [2, 10]\n",
      "The columns we are dropping are  ['Staff']\n",
      "\n",
      "The feature variables in X after the drop operation are\n",
      "    Country   Age   Salary      Cost   Days\n",
      "1     Spain  21.0  11000.0     120.0    3.0\n",
      "3     Spain  43.0  60000.0     510.0   15.0\n",
      "4    France  40.0  80000.0     910.0    8.0\n",
      "5   Germany  74.0  59000.0     520.0    5.0\n",
      "6   Germany   NaN  92000.0     800.0  500.0\n",
      "7    France  51.0  43000.0     420.0    6.0\n",
      "8    France  74.0      NaN     720.0    8.0\n",
      "9    France  73.0  25000.0     930.0   15.0\n",
      "11    Spain  44.0  94000.0     620.0   12.0\n",
      "12  Germany  25.0  22000.0    -200.0    9.0\n",
      "13  Germany  75.0  52000.0     740.0    4.0\n",
      "14      NaN  34.0  15000.0     870.0   19.0\n",
      "15  Germany   NaN  54000.0     370.0    6.0\n",
      "16   France  48.0  31000.0     610.0    7.0\n",
      "17   France  58.0  80000.0     280.0   11.0\n",
      "18  Germany  32.0  56000.0  200000.0    8.0\n",
      "19    Spain  34.0  51000.0     330.0  900.0\n",
      "20   France  55.0  59000.0     630.0    5.0\n",
      "21    Spain  50.0  54000.0     340.0   10.0\n",
      "22  Germany  62.0      NaN     680.0    7.0\n",
      "23   France  44.0  45000.0     900.0    5.0\n",
      "24      NaN  39.0  18000.0     480.0   14.0\n",
      "25    Spain  38.0  33000.0     600.0   20.0\n",
      "26   France  51.0  95000.0     250.0   14.0\n",
      "27    Spain  46.0  80000.0     250.0   13.0\n",
      "28   France  74.0  82000.0     320.0   14.0\n",
      "29  Germany  72.0  37000.0     450.0   11.0\n",
      "30    Spain  80.0  98000.0    1000.0    6.0\n",
      "\n",
      "The target variable values in y after the drop operation are\n",
      "1     Yes\n",
      "3     Yes\n",
      "4      No\n",
      "5     Yes\n",
      "6     Yes\n",
      "7      No\n",
      "8      No\n",
      "9     Yes\n",
      "11    Yes\n",
      "12     No\n",
      "13     No\n",
      "14    Yes\n",
      "15     No\n",
      "16     No\n",
      "17    Yes\n",
      "18    Yes\n",
      "19     No\n",
      "20     No\n",
      "21     No\n",
      "22    Yes\n",
      "23    Yes\n",
      "24     No\n",
      "25    Yes\n",
      "26     No\n",
      "27     No\n",
      "28    Yes\n",
      "29    Yes\n",
      "30     No\n",
      "Name: Purchased, dtype: object\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.7 # If more than 70% of the values in a row or column are missing, then only perform removal\n",
    "rows_to_drop = X.isnull().mean(axis=1) > threshold\n",
    "columns_to_drop = X.isnull().mean(axis=0) > threshold\n",
    "\n",
    "# Identify the index numbers of rows to drop and the names of columns to drop\n",
    "rows_to_drop_indices = X.index[rows_to_drop].tolist()\n",
    "columns_to_drop_names = X.columns[columns_to_drop].tolist()\n",
    "print (\"The rows we are dropping are \", rows_to_drop_indices)\n",
    "print (\"The columns we are dropping are \", columns_to_drop_names)\n",
    "\n",
    "# Perform the drop operation\n",
    "X = X.loc[~rows_to_drop, ~columns_to_drop]\n",
    "\n",
    "# Also need to remove the corresponding values for the dropped rows\n",
    "# from the target variable column based on their columns\n",
    "y = y.drop(index=rows_to_drop_indices)\n",
    "\n",
    "print (\"\\nThe feature variables in X after the drop operation are\")\n",
    "print (X)\n",
    "\n",
    "print (\"\\nThe target variable values in y after the drop operation are\")\n",
    "print (y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing data in categorical variable columns\n",
    "\n",
    "The Country column still has some missing data. \n",
    "\n",
    "There are many ways to handle this. The simplest is to impute these values with the most frequently occuring category (mode) in the column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The feature variables in X after imputation on the Country column are: \n",
      "    Country   Age   Salary      Cost   Days\n",
      "1     Spain  21.0  11000.0     120.0    3.0\n",
      "3     Spain  43.0  60000.0     510.0   15.0\n",
      "4    France  40.0  80000.0     910.0    8.0\n",
      "5   Germany  74.0  59000.0     520.0    5.0\n",
      "6   Germany   NaN  92000.0     800.0  500.0\n",
      "7    France  51.0  43000.0     420.0    6.0\n",
      "8    France  74.0      NaN     720.0    8.0\n",
      "9    France  73.0  25000.0     930.0   15.0\n",
      "11    Spain  44.0  94000.0     620.0   12.0\n",
      "12  Germany  25.0  22000.0    -200.0    9.0\n",
      "13  Germany  75.0  52000.0     740.0    4.0\n",
      "14   France  34.0  15000.0     870.0   19.0\n",
      "15  Germany   NaN  54000.0     370.0    6.0\n",
      "16   France  48.0  31000.0     610.0    7.0\n",
      "17   France  58.0  80000.0     280.0   11.0\n",
      "18  Germany  32.0  56000.0  200000.0    8.0\n",
      "19    Spain  34.0  51000.0     330.0  900.0\n",
      "20   France  55.0  59000.0     630.0    5.0\n",
      "21    Spain  50.0  54000.0     340.0   10.0\n",
      "22  Germany  62.0      NaN     680.0    7.0\n",
      "23   France  44.0  45000.0     900.0    5.0\n",
      "24   France  39.0  18000.0     480.0   14.0\n",
      "25    Spain  38.0  33000.0     600.0   20.0\n",
      "26   France  51.0  95000.0     250.0   14.0\n",
      "27    Spain  46.0  80000.0     250.0   13.0\n",
      "28   France  74.0  82000.0     320.0   14.0\n",
      "29  Germany  72.0  37000.0     450.0   11.0\n",
      "30    Spain  80.0  98000.0    1000.0    6.0\n"
     ]
    }
   ],
   "source": [
    "mode_value = X['Country'].mode()[0]\n",
    "X['Country'].fillna(mode_value, inplace=True)\n",
    "print (\"\\nThe feature variables in X after imputation on the Country column are: \")\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhfKXNxlSabC"
   },
   "source": [
    "## Checking for missing data and perform imputation if necessary\n",
    "\n",
    "For the remaining numeric columns that were not dropped, we can impute the missing cells with either the **mean, median or mode of all the other values in that column** as we have already seen before in previous example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the numeric columns : \n",
      "Age       2\n",
      "Salary    2\n",
      "Cost      0\n",
      "Days      0\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data in 'Age' and 'Salary' columns\n",
    "missing_data_check = X[['Age', 'Salary', 'Cost', 'Days']].isnull().sum()\n",
    "print(\"Number of missing values in the numeric columns : \")\n",
    "print (missing_data_check)\n",
    "print (type(missing_data_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables X after imputation:\n",
      "     Country   Age   Salary      Cost   Days\n",
      "1     Spain  21.0  11000.0     120.0    3.0\n",
      "3     Spain  43.0  60000.0     510.0   15.0\n",
      "4    France  40.0  80000.0     910.0    8.0\n",
      "5   Germany  74.0  59000.0     520.0    5.0\n",
      "6   Germany  51.0  92000.0     800.0  500.0\n",
      "7    France  51.0  43000.0     420.0    6.0\n",
      "8    France  74.0  54846.0     720.0    8.0\n",
      "9    France  73.0  25000.0     930.0   15.0\n",
      "11    Spain  44.0  94000.0     620.0   12.0\n",
      "12  Germany  25.0  22000.0    -200.0    9.0\n",
      "13  Germany  75.0  52000.0     740.0    4.0\n",
      "14   France  34.0  15000.0     870.0   19.0\n",
      "15  Germany  51.0  54000.0     370.0    6.0\n",
      "16   France  48.0  31000.0     610.0    7.0\n",
      "17   France  58.0  80000.0     280.0   11.0\n",
      "18  Germany  32.0  56000.0  200000.0    8.0\n",
      "19    Spain  34.0  51000.0     330.0  900.0\n",
      "20   France  55.0  59000.0     630.0    5.0\n",
      "21    Spain  50.0  54000.0     340.0   10.0\n",
      "22  Germany  62.0  54846.0     680.0    7.0\n",
      "23   France  44.0  45000.0     900.0    5.0\n",
      "24   France  39.0  18000.0     480.0   14.0\n",
      "25    Spain  38.0  33000.0     600.0   20.0\n",
      "26   France  51.0  95000.0     250.0   14.0\n",
      "27    Spain  46.0  80000.0     250.0   13.0\n",
      "28   France  74.0  82000.0     320.0   14.0\n",
      "29  Germany  72.0  37000.0     450.0   11.0\n",
      "30    Spain  80.0  98000.0    1000.0    6.0\n"
     ]
    }
   ],
   "source": [
    "# If there are missing values present in any of the numeric columns\n",
    "if missing_data_check.any():\n",
    "\n",
    "    for column in ['Age', 'Salary', 'Cost', 'Days']:\n",
    "       if missing_data_check[column] > 0:\n",
    "\n",
    "           #Impute missing data with the mean of the existing values in the respective column\n",
    "           \n",
    "           X[column].fillna(X[column].mean(), inplace=True)\n",
    "\n",
    "           # You can also impute with the median of the existing values in the respective column\n",
    "           # \n",
    "           #X[column].fillna(X[column].median(), inplace=True)\n",
    "\n",
    "           # You can also impute with the mode of the existing values in the respective column\n",
    "\n",
    "           #mode_value = X[column].mode()[0]\n",
    "           #X[column].fillna(mode_value, inplace=True)\n",
    "\n",
    "\n",
    "           \n",
    "           # Round the imputed values to the nearest integer\n",
    "           # Not necessary, but helps in displaying the column values neatly\n",
    "           X[column] = X[column].round()\n",
    "\n",
    "# Display modified X dataframe after imputation\n",
    "print(\"Feature variables X after imputation:\\n\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to detect outliers and impute them with mean of non-outliers\n",
    "\n",
    "\n",
    "There are many **custom algorithms** available for detecting outliers based on statistical techniques, each of them has their specific weakness and advantages\n",
    "\n",
    "The range of values that are considered normal so that anything outside this range is **highly subjective**\n",
    "\n",
    "Some algorithms will miss picking up extremely low value or high value outliers, while others may mistake slightly high or low values within normal rage as outliers\n",
    "\n",
    "This algorithm is different from the first one in the previous example and uses the MAD together with the median to figure out the range of normal numbers\n",
    "\n",
    "It is able to pick up outliers with very small values, but may also potentially incorrectly flag normal values as outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_outliers(df, column, z_threshold=3.5, lower_percentile=1, upper_percentile=99):\n",
    "    # Calculate percentiles\n",
    "    lower_bound = np.percentile(df[column], lower_percentile)\n",
    "    upper_bound = np.percentile(df[column], upper_percentile)\n",
    "    \n",
    "    # Calculate the median and MAD (Median Absolute Deviation)\n",
    "    median = df[column].median()\n",
    "    mad = np.median(np.abs(df[column] - median))\n",
    "    \n",
    "    # Calculate the modified Z-score\n",
    "    if mad == 0:\n",
    "        # If MAD is zero, then all data points are identical\n",
    "        modified_z_scores = np.zeros(len(df))\n",
    "    else:\n",
    "        modified_z_scores = 0.6745 * (df[column] - median) / mad\n",
    "    \n",
    "    # Detect outliers based on percentiles and modified Z-score\n",
    "    percentile_outliers = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "    z_score_outliers = np.abs(modified_z_scores) > z_threshold\n",
    "    combined_outliers = percentile_outliers | z_score_outliers\n",
    "    outlier_count = combined_outliers.sum()\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "\n",
    "        print (f\"Number of outliers detecting for column '{column}' is {outlier_count}\")\n",
    "        \n",
    "        # Calculate mean of non-outlier values\n",
    "        non_outlier_mean = int(df[~combined_outliers][column].mean())\n",
    "        \n",
    "        # Replace outliers with the mean of non-outlier values\n",
    "        df.loc[combined_outliers, column] = non_outlier_mean\n",
    "        print(f\"Outliers detected and imputed in column '{column}' with mean value {non_outlier_mean}\")\n",
    "    else:\n",
    "        print(f\"No outliers detected in column '{column}'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers detecting for column 'Cost' is 2\n",
      "Outliers detected and imputed in column 'Cost' with mean value 563\n",
      "Number of outliers detecting for column 'Days' is 3\n",
      "Outliers detected and imputed in column 'Days' with mean value 10\n"
     ]
    }
   ],
   "source": [
    "# Check and impute outliers for columns 'Cost' and 'Days'\n",
    "impute_outliers(X, 'Cost')\n",
    "impute_outliers(X, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables after detection and imputation of outliers\n",
      "    Country   Age   Salary    Cost  Days\n",
      "1     Spain  21.0  11000.0   120.0  10.0\n",
      "3     Spain  43.0  60000.0   510.0  15.0\n",
      "4    France  40.0  80000.0   910.0   8.0\n",
      "5   Germany  74.0  59000.0   520.0   5.0\n",
      "6   Germany  51.0  92000.0   800.0  10.0\n",
      "7    France  51.0  43000.0   420.0   6.0\n",
      "8    France  74.0  54846.0   720.0   8.0\n",
      "9    France  73.0  25000.0   930.0  15.0\n",
      "11    Spain  44.0  94000.0   620.0  12.0\n",
      "12  Germany  25.0  22000.0   563.0   9.0\n",
      "13  Germany  75.0  52000.0   740.0   4.0\n",
      "14   France  34.0  15000.0   870.0  19.0\n",
      "15  Germany  51.0  54000.0   370.0   6.0\n",
      "16   France  48.0  31000.0   610.0   7.0\n",
      "17   France  58.0  80000.0   280.0  11.0\n",
      "18  Germany  32.0  56000.0   563.0   8.0\n",
      "19    Spain  34.0  51000.0   330.0  10.0\n",
      "20   France  55.0  59000.0   630.0   5.0\n",
      "21    Spain  50.0  54000.0   340.0  10.0\n",
      "22  Germany  62.0  54846.0   680.0   7.0\n",
      "23   France  44.0  45000.0   900.0   5.0\n",
      "24   France  39.0  18000.0   480.0  14.0\n",
      "25    Spain  38.0  33000.0   600.0  20.0\n",
      "26   France  51.0  95000.0   250.0  14.0\n",
      "27    Spain  46.0  80000.0   250.0  13.0\n",
      "28   France  74.0  82000.0   320.0  14.0\n",
      "29  Germany  72.0  37000.0   450.0  11.0\n",
      "30    Spain  80.0  98000.0  1000.0   6.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables after detection and imputation of outliers\")\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform dummy encoding on categorical variables in dataset\n",
    "\n",
    "This is nearly identical to one hot encoding, except we drop one extra variable column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables after dummy encoding on the Country column\n",
      "    Age  Salary  Cost  Days  Country_Germany  Country_Spain\n",
      "1    21   11000   120    10                0              1\n",
      "3    43   60000   510    15                0              1\n",
      "4    40   80000   910     8                0              0\n",
      "5    74   59000   520     5                1              0\n",
      "6    51   92000   800    10                1              0\n",
      "7    51   43000   420     6                0              0\n",
      "8    74   54846   720     8                0              0\n",
      "9    73   25000   930    15                0              0\n",
      "11   44   94000   620    12                0              1\n",
      "12   25   22000   563     9                1              0\n",
      "13   75   52000   740     4                1              0\n",
      "14   34   15000   870    19                0              0\n",
      "15   51   54000   370     6                1              0\n",
      "16   48   31000   610     7                0              0\n",
      "17   58   80000   280    11                0              0\n",
      "18   32   56000   563     8                1              0\n",
      "19   34   51000   330    10                0              1\n",
      "20   55   59000   630     5                0              0\n",
      "21   50   54000   340    10                0              1\n",
      "22   62   54846   680     7                1              0\n",
      "23   44   45000   900     5                0              0\n",
      "24   39   18000   480    14                0              0\n",
      "25   38   33000   600    20                0              1\n",
      "26   51   95000   250    14                0              0\n",
      "27   46   80000   250    13                0              1\n",
      "28   74   82000   320    14                0              0\n",
      "29   72   37000   450    11                1              0\n",
      "30   80   98000  1000     6                0              1\n"
     ]
    }
   ],
   "source": [
    "# Perform dummy encoding on the 'Country' column in X\n",
    "X = pd.get_dummies(X, columns=['Country'], drop_first=True).astype(int)\n",
    "\n",
    "print (\"Feature variables after dummy encoding on the Country column\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform label encoding on the target variable\n",
    "\n",
    "The target variable must also be encoded in numeric format for many ML models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable column original values\n",
      "1     Yes\n",
      "3     Yes\n",
      "4      No\n",
      "5     Yes\n",
      "6     Yes\n",
      "7      No\n",
      "8      No\n",
      "9     Yes\n",
      "11    Yes\n",
      "12     No\n",
      "13     No\n",
      "14    Yes\n",
      "15     No\n",
      "16     No\n",
      "17    Yes\n",
      "18    Yes\n",
      "19     No\n",
      "20     No\n",
      "21     No\n",
      "22    Yes\n",
      "23    Yes\n",
      "24     No\n",
      "25    Yes\n",
      "26     No\n",
      "27     No\n",
      "28    Yes\n",
      "29    Yes\n",
      "30     No\n",
      "Name: Purchased, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (\"Target variable column original values\")\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding the Yes and No as 1 and 0\n",
      "[1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "print (\"After encoding the Yes and No as 1 and 0\")\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting original dataset into the Training set and Test set\n",
    "\n",
    "This is a fundamental practice in ML and is important for:\n",
    "* Evaluating model performance correctly\n",
    "* Avoiding overfitting\n",
    "* Preventing data leakage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3333, random_state = 1)\n",
    "\n",
    "# We use a fixed value for the random state parameter so that the split will always use the same rows for the training and test data set \n",
    "# This is ensure reproducibility of this ML project, which is important to verify performance evaluations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 rows in the training dataset\n",
      "\n",
      "The feature variable values are\n",
      "    Age  Salary  Cost  Days  Country_Germany  Country_Spain\n",
      "4    40   80000   910     8                0              0\n",
      "26   51   95000   250    14                0              0\n",
      "8    74   54846   720     8                0              0\n",
      "21   50   54000   340    10                0              1\n",
      "16   48   31000   610     7                0              0\n",
      "9    73   25000   930    15                0              0\n",
      "28   74   82000   320    14                0              0\n",
      "3    43   60000   510    15                0              1\n",
      "19   34   51000   330    10                0              1\n",
      "1    21   11000   120    10                0              1\n",
      "18   32   56000   563     8                1              0\n",
      "30   80   98000  1000     6                0              1\n",
      "29   72   37000   450    11                1              0\n",
      "12   25   22000   563     9                1              0\n",
      "11   44   94000   620    12                0              1\n",
      "15   51   54000   370     6                1              0\n",
      "14   34   15000   870    19                0              0\n",
      "7    51   43000   420     6                0              0\n",
      "\n",
      "The target variable values are\n",
      "[0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print (f\"There are {len(X_train)} rows in the training dataset\\n\")\n",
    "print (\"The feature variable values are\")\n",
    "print (X_train)\n",
    "\n",
    "print (\"\\nThe target variable values are\")\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 rows in the test dataset\n",
      "\n",
      "The feature variable values are\n",
      "    Age  Salary  Cost  Days  Country_Germany  Country_Spain\n",
      "27   46   80000   250    13                0              1\n",
      "20   55   59000   630     5                0              0\n",
      "22   62   54846   680     7                1              0\n",
      "23   44   45000   900     5                0              0\n",
      "17   58   80000   280    11                0              0\n",
      "5    74   59000   520     5                1              0\n",
      "25   38   33000   600    20                0              1\n",
      "13   75   52000   740     4                1              0\n",
      "24   39   18000   480    14                0              0\n",
      "6    51   92000   800    10                1              0\n",
      "\n",
      "The target variable values are\n",
      "[0 0 1 1 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print (f\"There are {len(X_test)} rows in the test dataset\\n\")\n",
    "print (\"The feature variable values are\")\n",
    "print (X_test)\n",
    "\n",
    "print (\"\\nThe target variable values are\")\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "This should be done (rather than before) after train test split to avoid data leakage that may contribute to poor model \n",
    "performance in production\n",
    "\n",
    "There are two commonly used types of feature scaling: **standardization** and **normalization**\n",
    "\n",
    "Here we are using **normalization**, which scales the data such that the distribution of values in the feature column is between 0 and 1 or -1 and 1\n",
    "\n",
    "For default normalization in sklearn, most values will lie within the **range of approximately 0 and 1** \n",
    "\n",
    "Also note that we perform feature scaling only on the columns that were originally numeric, and do not include columns with numbers that result from categorical encoding such as dummy encoding that we did earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train.iloc[:, 0:4] = sc.fit_transform(X_train.iloc[:, 0:4])\n",
    "\n",
    "# Transform the test data\n",
    "X_test.iloc[:, 0:4] = sc.transform(X_test.iloc[:, 0:4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables in training dataset after standardization\n",
      "         Age    Salary      Cost      Days  Country_Germany  Country_Spain\n",
      "4   0.322034  0.793103  0.897727  0.153846                0              0\n",
      "26  0.508475  0.965517  0.147727  0.615385                0              0\n",
      "8   0.898305  0.503977  0.681818  0.153846                0              0\n",
      "21  0.491525  0.494253  0.250000  0.307692                0              1\n",
      "16  0.457627  0.229885  0.556818  0.076923                0              0\n",
      "9   0.881356  0.160920  0.920455  0.692308                0              0\n",
      "28  0.898305  0.816092  0.227273  0.615385                0              0\n",
      "3   0.372881  0.563218  0.443182  0.692308                0              1\n",
      "19  0.220339  0.459770  0.238636  0.307692                0              1\n",
      "1   0.000000  0.000000  0.000000  0.307692                0              1\n",
      "18  0.186441  0.517241  0.503409  0.153846                1              0\n",
      "30  1.000000  1.000000  1.000000  0.000000                0              1\n",
      "29  0.864407  0.298851  0.375000  0.384615                1              0\n",
      "12  0.067797  0.126437  0.503409  0.230769                1              0\n",
      "11  0.389831  0.954023  0.568182  0.461538                0              1\n",
      "15  0.508475  0.494253  0.284091  0.000000                1              0\n",
      "14  0.220339  0.045977  0.852273  1.000000                0              0\n",
      "7   0.508475  0.367816  0.340909  0.000000                0              0\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables in training dataset after standardization\")\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables in test dataset after standardization\n",
      "         Age    Salary      Cost      Days  Country_Germany  Country_Spain\n",
      "27  0.423729  0.793103  0.147727  0.538462                0              1\n",
      "20  0.576271  0.551724  0.579545 -0.076923                0              0\n",
      "22  0.694915  0.503977  0.636364  0.076923                1              0\n",
      "23  0.389831  0.390805  0.886364 -0.076923                0              0\n",
      "17  0.627119  0.793103  0.181818  0.384615                0              0\n",
      "5   0.898305  0.551724  0.454545 -0.076923                1              0\n",
      "25  0.288136  0.252874  0.545455  1.076923                0              1\n",
      "13  0.915254  0.471264  0.704545 -0.153846                1              0\n",
      "24  0.305085  0.080460  0.409091  0.615385                0              0\n",
      "6   0.508475  0.931034  0.772727  0.307692                1              0\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables in test dataset after standardization\")\n",
    "print (X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing_tools.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
