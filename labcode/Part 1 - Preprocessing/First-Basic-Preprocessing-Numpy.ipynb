{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37puETfgRzzg"
   },
   "source": [
    "# Repeat data preprocessing steps : Using NumPy arrays for Vers 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "## Importing the dataset\n",
    "\n",
    "To make things simple, we usually structure the dataset so that the target variable column is the last column in the table\n",
    "\n",
    "*  **X typically denotes the feature variables**, which are all the columns in the table except the last one\n",
    "* **y typically denotes the single target variable**, which is the last column in the table\n",
    "\n",
    "Here we additionally use the values property on X and y (which are originally Dataframes) to convert the data to Numpy arrays. \n",
    "\n",
    "Working with Numpy arrays instead of Pandas Dataframes is done for a variety of reasons:\n",
    "\n",
    "* Performance considerations\n",
    "\n",
    "* Avoiding Pandas Overhead\n",
    "\n",
    "* Integration with libraries that require NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwEPNDWySTKm"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('sample-data-proprocessing-v1.csv')\n",
    "X = dataset.iloc[  :  , :-1].values\n",
    "y = dataset.iloc[  :  , -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "hCsz2yCebe1R",
    "outputId": "1e4cc568-4e51-4b38-9d46-4aa3f15204be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature variable columns in X are\n",
      "[['Spain' 21.0 11000.0 120 3]\n",
      " ['France' 45.0 32000.0 330 7]\n",
      " ['Spain' 43.0 60000.0 510 15]\n",
      " ['France' 40.0 80000.0 910 8]\n",
      " ['Germany' 74.0 59000.0 520 5]\n",
      " ['Germany' nan 92000.0 800 500]\n",
      " ['France' 51.0 43000.0 420 6]\n",
      " ['France' 74.0 nan 720 8]\n",
      " ['France' 73.0 25000.0 930 15]\n",
      " ['Spain' 65.0 85000.0 410 13]\n",
      " ['Spain' 44.0 94000.0 620 12]\n",
      " ['Germany' 25.0 22000.0 -200 9]\n",
      " ['Germany' 75.0 52000.0 740 4]\n",
      " ['Spain' 34.0 15000.0 870 19]\n",
      " ['Germany' nan 54000.0 370 6]\n",
      " ['France' 48.0 31000.0 610 7]\n",
      " ['France' 58.0 80000.0 280 11]\n",
      " ['Germany' 32.0 56000.0 200000 8]\n",
      " ['Spain' 34.0 51000.0 330 900]\n",
      " ['France' 55.0 59000.0 630 5]\n",
      " ['Spain' 50.0 54000.0 340 10]\n",
      " ['Germany' 62.0 nan 680 7]\n",
      " ['France' 44.0 45000.0 900 5]\n",
      " ['France' 39.0 18000.0 480 14]\n",
      " ['Spain' 38.0 33000.0 600 20]\n",
      " ['France' 51.0 95000.0 250 14]\n",
      " ['Spain' 46.0 80000.0 250 13]\n",
      " ['France' 74.0 82000.0 320 14]\n",
      " ['Germany' 72.0 37000.0 450 11]\n",
      " ['Spain' 80.0 98000.0 1000 6]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"The feature variable columns in X are\")\n",
    "print (X)\n",
    "print (type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eYrOQ43XcJR3",
    "outputId": "e0873b2a-3b08-4bab-ef0d-15b88858ca44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target variable column values are : \n",
      "['Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No' 'No'\n",
      " 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No'\n",
      " 'No' 'Yes' 'Yes' 'No']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print (\"The target variable column values are : \")\n",
    "print(y)\n",
    "print (type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhfKXNxlSabC"
   },
   "source": [
    "## Checking for missing data and perform imputation if necessary\n",
    "\n",
    "We can impute the missing cells with either the **mean, median or mode of all the other values in that column**\n",
    "\n",
    "In this case, since we are working with NumPy arrays rather than Pandas dataframes, we will use specific methods from sklearn that are designed for these array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables X after imputation:\n",
      "\n",
      "[['Spain' 21.0 11000.0 120.0 3.0]\n",
      " ['France' 45.0 32000.0 330.0 7.0]\n",
      " ['Spain' 43.0 60000.0 510.0 15.0]\n",
      " ['France' 40.0 80000.0 910.0 8.0]\n",
      " ['Germany' 74.0 59000.0 520.0 5.0]\n",
      " ['Germany' 51.67857142857143 92000.0 800.0 500.0]\n",
      " ['France' 51.0 43000.0 420.0 6.0]\n",
      " ['France' 74.0 55107.142857142855 720.0 8.0]\n",
      " ['France' 73.0 25000.0 930.0 15.0]\n",
      " ['Spain' 65.0 85000.0 410.0 13.0]\n",
      " ['Spain' 44.0 94000.0 620.0 12.0]\n",
      " ['Germany' 25.0 22000.0 -200.0 9.0]\n",
      " ['Germany' 75.0 52000.0 740.0 4.0]\n",
      " ['Spain' 34.0 15000.0 870.0 19.0]\n",
      " ['Germany' 51.67857142857143 54000.0 370.0 6.0]\n",
      " ['France' 48.0 31000.0 610.0 7.0]\n",
      " ['France' 58.0 80000.0 280.0 11.0]\n",
      " ['Germany' 32.0 56000.0 200000.0 8.0]\n",
      " ['Spain' 34.0 51000.0 330.0 900.0]\n",
      " ['France' 55.0 59000.0 630.0 5.0]\n",
      " ['Spain' 50.0 54000.0 340.0 10.0]\n",
      " ['Germany' 62.0 55107.142857142855 680.0 7.0]\n",
      " ['France' 44.0 45000.0 900.0 5.0]\n",
      " ['France' 39.0 18000.0 480.0 14.0]\n",
      " ['Spain' 38.0 33000.0 600.0 20.0]\n",
      " ['France' 51.0 95000.0 250.0 14.0]\n",
      " ['Spain' 46.0 80000.0 250.0 13.0]\n",
      " ['France' 74.0 82000.0 320.0 14.0]\n",
      " ['Germany' 72.0 37000.0 450.0 11.0]\n",
      " ['Spain' 80.0 98000.0 1000.0 6.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# There is no direct code or method to explicitly handle NaN detection in a NumPy array\n",
    "# equivalent to isNull method of dataframe, so we just determine through visual inspection which \n",
    "# arrays to perform imputation on\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 1: ]) # From the 2nd column until the end \n",
    "X[:, 1: ] = imputer.transform(X[:, 1: ])\n",
    "print(\"Feature variables X after imputation:\\n\")\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Country        Age        Salary      Cost   Days\n",
      "0     Spain       21.0       11000.0     120.0    3.0\n",
      "1    France       45.0       32000.0     330.0    7.0\n",
      "2     Spain       43.0       60000.0     510.0   15.0\n",
      "3    France       40.0       80000.0     910.0    8.0\n",
      "4   Germany       74.0       59000.0     520.0    5.0\n",
      "5   Germany  51.678571       92000.0     800.0  500.0\n",
      "6    France       51.0       43000.0     420.0    6.0\n",
      "7    France       74.0  55107.142857     720.0    8.0\n",
      "8    France       73.0       25000.0     930.0   15.0\n",
      "9     Spain       65.0       85000.0     410.0   13.0\n",
      "10    Spain       44.0       94000.0     620.0   12.0\n",
      "11  Germany       25.0       22000.0    -200.0    9.0\n",
      "12  Germany       75.0       52000.0     740.0    4.0\n",
      "13    Spain       34.0       15000.0     870.0   19.0\n",
      "14  Germany  51.678571       54000.0     370.0    6.0\n",
      "15   France       48.0       31000.0     610.0    7.0\n",
      "16   France       58.0       80000.0     280.0   11.0\n",
      "17  Germany       32.0       56000.0  200000.0    8.0\n",
      "18    Spain       34.0       51000.0     330.0  900.0\n",
      "19   France       55.0       59000.0     630.0    5.0\n",
      "20    Spain       50.0       54000.0     340.0   10.0\n",
      "21  Germany       62.0  55107.142857     680.0    7.0\n",
      "22   France       44.0       45000.0     900.0    5.0\n",
      "23   France       39.0       18000.0     480.0   14.0\n",
      "24    Spain       38.0       33000.0     600.0   20.0\n",
      "25   France       51.0       95000.0     250.0   14.0\n",
      "26    Spain       46.0       80000.0     250.0   13.0\n",
      "27   France       74.0       82000.0     320.0   14.0\n",
      "28  Germany       72.0       37000.0     450.0   11.0\n",
      "29    Spain       80.0       98000.0    1000.0    6.0\n"
     ]
    }
   ],
   "source": [
    "# At this point we will need to convert the 2D numpy array to a dataframe \n",
    "# to perform the function to detect outliers and impute them\n",
    "# as the functionality is too complex to implement completely using Numpy methods\n",
    "X_df = pd.DataFrame(X, columns=['Country', 'Age', 'Salary', 'Cost', 'Days'])\n",
    "print (X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to detect outliers and impute them with mean of non-outliers\n",
    "\n",
    "We will reuse the same **custom algorithms** that we used previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_outliers(df, column):\n",
    "    # Calculate the first and third quartile\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Check if there are any outliers\n",
    "    outliers = ((df[column] < lower_bound) | (df[column] > upper_bound))\n",
    "    outlier_count = outliers.sum()\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "\n",
    "        print (f\"Number of outliers detecting for column '{column}' is {outlier_count}\")\n",
    "        \n",
    "        # Calculate mean of non-outlier values\n",
    "        non_outlier_mean = int(df[~outliers][column].mean())\n",
    "        \n",
    "        # Replace outliers with the mean of non-outlier values\n",
    "        df.loc[outliers, column] = non_outlier_mean\n",
    "        print(f\"Outliers detected and imputed in column '{column}' with mean value {non_outlier_mean}\")\n",
    "    else:\n",
    "        print(f\"No outliers detected in column '{column}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers detecting for column 'Cost' is 1\n",
      "Outliers detected and imputed in column 'Cost' with mean value 523\n",
      "Number of outliers detecting for column 'Days' is 2\n",
      "Outliers detected and imputed in column 'Days' with mean value 9\n"
     ]
    }
   ],
   "source": [
    "# Check and impute outliers for columns 'Cost' and 'Days'\n",
    "impute_outliers(X_df, 'Cost')\n",
    "impute_outliers(X_df, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables after detection and imputation of outliers\n",
      "    Country        Age        Salary    Cost  Days\n",
      "0     Spain       21.0       11000.0   120.0   3.0\n",
      "1    France       45.0       32000.0   330.0   7.0\n",
      "2     Spain       43.0       60000.0   510.0  15.0\n",
      "3    France       40.0       80000.0   910.0   8.0\n",
      "4   Germany       74.0       59000.0   520.0   5.0\n",
      "5   Germany  51.678571       92000.0   800.0     9\n",
      "6    France       51.0       43000.0   420.0   6.0\n",
      "7    France       74.0  55107.142857   720.0   8.0\n",
      "8    France       73.0       25000.0   930.0  15.0\n",
      "9     Spain       65.0       85000.0   410.0  13.0\n",
      "10    Spain       44.0       94000.0   620.0  12.0\n",
      "11  Germany       25.0       22000.0  -200.0   9.0\n",
      "12  Germany       75.0       52000.0   740.0   4.0\n",
      "13    Spain       34.0       15000.0   870.0  19.0\n",
      "14  Germany  51.678571       54000.0   370.0   6.0\n",
      "15   France       48.0       31000.0   610.0   7.0\n",
      "16   France       58.0       80000.0   280.0  11.0\n",
      "17  Germany       32.0       56000.0     523   8.0\n",
      "18    Spain       34.0       51000.0   330.0     9\n",
      "19   France       55.0       59000.0   630.0   5.0\n",
      "20    Spain       50.0       54000.0   340.0  10.0\n",
      "21  Germany       62.0  55107.142857   680.0   7.0\n",
      "22   France       44.0       45000.0   900.0   5.0\n",
      "23   France       39.0       18000.0   480.0  14.0\n",
      "24    Spain       38.0       33000.0   600.0  20.0\n",
      "25   France       51.0       95000.0   250.0  14.0\n",
      "26    Spain       46.0       80000.0   250.0  13.0\n",
      "27   France       74.0       82000.0   320.0  14.0\n",
      "28  Germany       72.0       37000.0   450.0  11.0\n",
      "29    Spain       80.0       98000.0  1000.0   6.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables after detection and imputation of outliers\")\n",
    "print (X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables in a 2d Numpy array\n",
      "[['Spain' 21.0 11000.0 120.0 3.0]\n",
      " ['France' 45.0 32000.0 330.0 7.0]\n",
      " ['Spain' 43.0 60000.0 510.0 15.0]\n",
      " ['France' 40.0 80000.0 910.0 8.0]\n",
      " ['Germany' 74.0 59000.0 520.0 5.0]\n",
      " ['Germany' 51.67857142857143 92000.0 800.0 9]\n",
      " ['France' 51.0 43000.0 420.0 6.0]\n",
      " ['France' 74.0 55107.142857142855 720.0 8.0]\n",
      " ['France' 73.0 25000.0 930.0 15.0]\n",
      " ['Spain' 65.0 85000.0 410.0 13.0]\n",
      " ['Spain' 44.0 94000.0 620.0 12.0]\n",
      " ['Germany' 25.0 22000.0 -200.0 9.0]\n",
      " ['Germany' 75.0 52000.0 740.0 4.0]\n",
      " ['Spain' 34.0 15000.0 870.0 19.0]\n",
      " ['Germany' 51.67857142857143 54000.0 370.0 6.0]\n",
      " ['France' 48.0 31000.0 610.0 7.0]\n",
      " ['France' 58.0 80000.0 280.0 11.0]\n",
      " ['Germany' 32.0 56000.0 523 8.0]\n",
      " ['Spain' 34.0 51000.0 330.0 9]\n",
      " ['France' 55.0 59000.0 630.0 5.0]\n",
      " ['Spain' 50.0 54000.0 340.0 10.0]\n",
      " ['Germany' 62.0 55107.142857142855 680.0 7.0]\n",
      " ['France' 44.0 45000.0 900.0 5.0]\n",
      " ['France' 39.0 18000.0 480.0 14.0]\n",
      " ['Spain' 38.0 33000.0 600.0 20.0]\n",
      " ['France' 51.0 95000.0 250.0 14.0]\n",
      " ['Spain' 46.0 80000.0 250.0 13.0]\n",
      " ['France' 74.0 82000.0 320.0 14.0]\n",
      " ['Germany' 72.0 37000.0 450.0 11.0]\n",
      " ['Spain' 80.0 98000.0 1000.0 6.0]]\n"
     ]
    }
   ],
   "source": [
    "# Now we can convert the Dataframe back to a 2d Numpy array for further processing\n",
    "X = X_df.to_numpy()\n",
    "print (\"Feature variables in a 2d Numpy array\")\n",
    "print (X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CriG6VzVSjcK"
   },
   "source": [
    "## Perform one hot encoding on categorical variables in dataset\n",
    "\n",
    "Here, we will again use methods from the sklearn module specific for this purpose \n",
    "as we will not be using the Pandas get_dummies method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hwuVddlSwVi"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "f7QspewyeBfx",
    "outputId": "5b35feef-7fe2-46ef-ce70-80495f94f4ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables after one hot encoding on the Country column\n",
      "[[0.0 0.0 1.0 21.0 11000.0 120.0 3.0]\n",
      " [1.0 0.0 0.0 45.0 32000.0 330.0 7.0]\n",
      " [0.0 0.0 1.0 43.0 60000.0 510.0 15.0]\n",
      " [1.0 0.0 0.0 40.0 80000.0 910.0 8.0]\n",
      " [0.0 1.0 0.0 74.0 59000.0 520.0 5.0]\n",
      " [0.0 1.0 0.0 51.67857142857143 92000.0 800.0 9]\n",
      " [1.0 0.0 0.0 51.0 43000.0 420.0 6.0]\n",
      " [1.0 0.0 0.0 74.0 55107.142857142855 720.0 8.0]\n",
      " [1.0 0.0 0.0 73.0 25000.0 930.0 15.0]\n",
      " [0.0 0.0 1.0 65.0 85000.0 410.0 13.0]\n",
      " [0.0 0.0 1.0 44.0 94000.0 620.0 12.0]\n",
      " [0.0 1.0 0.0 25.0 22000.0 -200.0 9.0]\n",
      " [0.0 1.0 0.0 75.0 52000.0 740.0 4.0]\n",
      " [0.0 0.0 1.0 34.0 15000.0 870.0 19.0]\n",
      " [0.0 1.0 0.0 51.67857142857143 54000.0 370.0 6.0]\n",
      " [1.0 0.0 0.0 48.0 31000.0 610.0 7.0]\n",
      " [1.0 0.0 0.0 58.0 80000.0 280.0 11.0]\n",
      " [0.0 1.0 0.0 32.0 56000.0 523 8.0]\n",
      " [0.0 0.0 1.0 34.0 51000.0 330.0 9]\n",
      " [1.0 0.0 0.0 55.0 59000.0 630.0 5.0]\n",
      " [0.0 0.0 1.0 50.0 54000.0 340.0 10.0]\n",
      " [0.0 1.0 0.0 62.0 55107.142857142855 680.0 7.0]\n",
      " [1.0 0.0 0.0 44.0 45000.0 900.0 5.0]\n",
      " [1.0 0.0 0.0 39.0 18000.0 480.0 14.0]\n",
      " [0.0 0.0 1.0 38.0 33000.0 600.0 20.0]\n",
      " [1.0 0.0 0.0 51.0 95000.0 250.0 14.0]\n",
      " [0.0 0.0 1.0 46.0 80000.0 250.0 13.0]\n",
      " [1.0 0.0 0.0 74.0 82000.0 320.0 14.0]\n",
      " [0.0 1.0 0.0 72.0 37000.0 450.0 11.0]\n",
      " [0.0 0.0 1.0 80.0 98000.0 1000.0 6.0]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables after one hot encoding on the Country column\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXh8oVSITIc6"
   },
   "source": [
    "## Perform label encoding on the target variable\n",
    "\n",
    "For this case, we will use the LabelEncoder from sklearn which is also what we did for the case when y was a Pandas series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable column original values\n",
      "['Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No' 'No'\n",
      " 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No'\n",
      " 'No' 'Yes' 'Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "print (\"Target variable column original values\")\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding the Yes and No as 1 and 0\n",
      "[1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "print (\"After encoding the Yes and No as 1 and 0\")\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qb_vcgm3qZKW"
   },
   "source": [
    "## Splitting original dataset into the Training set and Test set\n",
    "\n",
    "The code here is exactly identical as for the case when X and y are Dataframes and Series objects\n",
    "\n",
    "The train_test_split method is designed to accept Numpy arrays as well as DataFrames and Series objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXgA6CzlqbCl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3333, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "GuwQhFdKrYTM",
    "outputId": "de1e527f-c229-4daf-e7c5-ea9d2485148d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 rows in the training dataset\n",
      "\n",
      "The feature variable values are\n",
      "[[1.0 0.0 0.0 39.0 18000.0 480.0 14.0]\n",
      " [0.0 1.0 0.0 74.0 59000.0 520.0 5.0]\n",
      " [0.0 0.0 1.0 43.0 60000.0 510.0 15.0]\n",
      " [1.0 0.0 0.0 51.0 95000.0 250.0 14.0]\n",
      " [1.0 0.0 0.0 51.0 43000.0 420.0 6.0]\n",
      " [0.0 0.0 1.0 34.0 51000.0 330.0 9]\n",
      " [0.0 0.0 1.0 34.0 15000.0 870.0 19.0]\n",
      " [1.0 0.0 0.0 74.0 55107.142857142855 720.0 8.0]\n",
      " [1.0 0.0 0.0 74.0 82000.0 320.0 14.0]\n",
      " [1.0 0.0 0.0 45.0 32000.0 330.0 7.0]\n",
      " [1.0 0.0 0.0 58.0 80000.0 280.0 11.0]\n",
      " [0.0 0.0 1.0 21.0 11000.0 120.0 3.0]\n",
      " [1.0 0.0 0.0 48.0 31000.0 610.0 7.0]\n",
      " [0.0 0.0 1.0 80.0 98000.0 1000.0 6.0]\n",
      " [0.0 1.0 0.0 72.0 37000.0 450.0 11.0]\n",
      " [0.0 0.0 1.0 65.0 85000.0 410.0 13.0]\n",
      " [1.0 0.0 0.0 73.0 25000.0 930.0 15.0]\n",
      " [0.0 1.0 0.0 75.0 52000.0 740.0 4.0]\n",
      " [0.0 1.0 0.0 25.0 22000.0 -200.0 9.0]\n",
      " [0.0 1.0 0.0 51.67857142857143 92000.0 800.0 9]]\n",
      "\n",
      "The target variable values are\n",
      "[0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print (f\"There are {len(X_train)} rows in the training dataset\\n\")\n",
    "print (\"The feature variable values are\")\n",
    "print (X_train)\n",
    "\n",
    "print (\"\\nThe target variable values are\")\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "TUrX_Tvcrbi4",
    "outputId": "9a041a9b-2642-4828-fa2f-a431d7d77631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 rows in the test dataset\n",
      "\n",
      "The feature variable values are\n",
      "[[0.0 1.0 0.0 32.0 56000.0 523 8.0]\n",
      " [0.0 1.0 0.0 62.0 55107.142857142855 680.0 7.0]\n",
      " [0.0 0.0 1.0 44.0 94000.0 620.0 12.0]\n",
      " [1.0 0.0 0.0 55.0 59000.0 630.0 5.0]\n",
      " [0.0 1.0 0.0 51.67857142857143 54000.0 370.0 6.0]\n",
      " [0.0 0.0 1.0 50.0 54000.0 340.0 10.0]\n",
      " [0.0 0.0 1.0 46.0 80000.0 250.0 13.0]\n",
      " [1.0 0.0 0.0 40.0 80000.0 910.0 8.0]\n",
      " [0.0 0.0 1.0 38.0 33000.0 600.0 20.0]\n",
      " [1.0 0.0 0.0 44.0 45000.0 900.0 5.0]]\n",
      "\n",
      "The target variable values are\n",
      "[1 1 1 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print (f\"There are {len(X_test)} rows in the test dataset\\n\")\n",
    "print (\"The feature variable values are\")\n",
    "print (X_test)\n",
    "\n",
    "print (\"\\nThe target variable values are\")\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpGqbS4TqkIR"
   },
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Here we also use the same objects StandardScaler from sklearn, and the code is nearly identical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxjSUXFQqo-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
    "\n",
    "# Transform the test data\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "DWPET8ZdlMnu",
    "outputId": "dea86927-5124-4e2a-e974-2804df9a913c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables in training dataset after standardization\n",
      "[[1.0 0.0 0.0 -0.8632009950207814 -1.2291519650612563\n",
      "  -0.05074934819224496 0.9586637990406123]\n",
      " [0.0 1.0 0.0 1.100668941416516 0.24631878925496908 0.08924885371739631\n",
      "  -1.1717001988274145]\n",
      " [0.0 0.0 1.0 -0.6387587165708045 0.2823058808236575 0.054249303239985995\n",
      "  1.1953709099148375]\n",
      " [1.0 0.0 0.0 -0.18987415967085083 1.5418540857277523 -0.8557390091726823\n",
      "  0.9586637990406123]\n",
      " [1.0 0.0 0.0 -0.18987415967085083 -0.3294746758440457\n",
      "  -0.26074665105670686 -0.9349930879531894]\n",
      " [0.0 0.0 1.0 -1.1437538430832523 -0.04157794329453831\n",
      "  -0.5757426053533997 -0.2248717553305138]\n",
      " [0.0 0.0 1.0 -1.1437538430832523 -1.3371132397673215 1.3142331204267574\n",
      "  2.1421993534117383]\n",
      " [1.0 0.0 0.0 1.100668941416516 0.10622618279114622 0.7892398632656027\n",
      "  -0.461578866204739]\n",
      " [1.0 0.0 0.0 1.100668941416516 1.0740218953348029 -0.61074215583081\n",
      "  0.9586637990406123]\n",
      " [1.0 0.0 0.0 -0.5265375773458161 -0.7253326830996183 -0.5757426053533997\n",
      "  -0.6982859770789642]\n",
      " [1.0 0.0 0.0 0.20289982761660866 1.002047712197426 -0.7507403577404513\n",
      "  0.24854246641793665]\n",
      " [0.0 0.0 1.0 -1.8731912480456772 -1.4810616060420752 -1.3107331653790164\n",
      "  -1.645114420575865]\n",
      " [1.0 0.0 0.0 -0.35820586850833347 -0.7613197746683068 0.4042448080140892\n",
      "  -0.6982859770789642]\n",
      " [0.0 0.0 1.0 1.4373323590914813 1.6498153604338175 1.7692272766330917\n",
      "  -0.9349930879531894]\n",
      " [0.0 1.0 0.0 0.9884478021915276 -0.5453972252561762 -0.1557479996244759\n",
      "  0.24854246641793665]\n",
      " [0.0 0.0 1.0 0.5956738149040681 1.181983170040868 -0.2957462015341172\n",
      "  0.721956688166387]\n",
      " [1.0 0.0 0.0 1.044558371804022 -0.9772423240804373 1.5242304232912194\n",
      "  1.1953709099148375]\n",
      " [0.0 1.0 0.0 1.1567795110290102 -0.005590851725849884 0.8592389642204233\n",
      "  -1.4084073097016399]\n",
      " [0.0 1.0 0.0 -1.6487489695957003 -1.0852035987865025 -2.4307187806561465\n",
      "  -0.2248717553305138]\n",
      " [0.0 1.0 0.0 -0.15179913029094394 1.433892811021687 1.0692362670848852\n",
      "  -0.2248717553305138]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables in training dataset after standardization\")\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sTXykB_QlRjE",
    "outputId": "b68f0cfc-d07c-48cb-80d0-6800028c41f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature variables in test dataset after standardization\n",
      "[[0.0 1.0 0.0 -1.255974982308241 0.1383575145489038 0.09974871886061941\n",
      "  -0.461578866204739]\n",
      " [0.0 1.0 0.0 0.4273421060665855 0.10622618279114622 0.6492416613559614\n",
      "  -0.6982859770789642]\n",
      " [0.0 0.0 1.0 -0.5826481469583104 1.5058669941590639 0.4392443584914995\n",
      "  0.48524957729216184]\n",
      " [1.0 0.0 0.0 0.034568118779126016 0.24631878925496908 0.4742439089689098\n",
      "  -1.1717001988274145]\n",
      " [0.0 1.0 0.0 -0.15179913029094394 0.06638333141152697\n",
      "  -0.4357444034437585 -0.9349930879531894]\n",
      " [0.0 0.0 1.0 -0.24598472928334505 0.06638333141152697\n",
      "  -0.5407430548759894 0.011835355543711429]\n",
      " [0.0 0.0 1.0 -0.4704270077333219 1.002047712197426 -0.8557390091726823\n",
      "  0.721956688166387]\n",
      " [1.0 0.0 0.0 -0.8070904254082871 1.002047712197426 1.4542313223363987\n",
      "  -0.461578866204739]\n",
      " [0.0 0.0 1.0 -0.9193115646332756 -0.6893455915309299 0.36924525753667886\n",
      "  2.3789064642859636]\n",
      " [1.0 0.0 0.0 -0.5826481469583104 -0.25750049270666886 1.4192317718589884\n",
      "  -1.1717001988274145]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature variables in test dataset after standardization\")\n",
    "print (X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing_tools.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
